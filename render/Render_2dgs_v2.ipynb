{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.insert(0, parent_dir)\n",
    "\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd().split('render')[0],'gaussian_data'))\n",
    "sys.path.insert(0, parent_dir)\n",
    "\n",
    "from gaussian_data.Camera import Camera\n",
    "from gaussian_data.Frame import Frame\n",
    "import gaussian_data.Plotters\n",
    "import gaussian_data.Utils as Utils\n",
    "\n",
    "from GaussianSplat import GaussianSplat\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from plyfile import PlyData\n",
    "import numpy as np\n",
    "import argparse\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "import Plotters\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "import scipy.io\n",
    "import pandas as pd\n",
    "from Render import Render\n",
    "\n",
    "%matplotlib qt\n",
    "\n",
    "# load hull\n",
    "path = 'I:/My Drive/Research/gs_data/mov19_2022_03_03/'\n",
    "real_coord = scipy.io.loadmat(f'{path}/3d_pts/real_coord.mat')['all_coords']\n",
    "points_3d = {body_wing : pd.DataFrame(Utils.load_hull(body_wing,path),columns = ['X','Y','Z','frame']) for body_wing in ['body','rwing','lwing']}\n",
    "# initilize objects\n",
    "frames = [1483]#list(range(500,700,13))\n",
    "\n",
    "image_names,points_in_idx = Utils.define_frames(frames,points_3d)\n",
    "cameras = {f'cam{cam + 1}':Camera(path,cam) for cam in range(4)}\n",
    "frames = {f'{im_name}.jpg':Frame(path,im_name,points_in_idx[im_name.split('CAM')[0]],real_coord,idx) for idx,im_name in enumerate(image_names)}\n",
    "# map 3d voxels to 2d pixels\n",
    "[frames[im_name].map_3d_2d(croped_image = True) for im_name in frames.keys()]\n",
    "voxel_dict,colors_dict = Utils.get_dict_for_points3d(frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from plyfile import PlyData\n",
    "import sh_utils\n",
    "import trimesh\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "%matplotlib qt\n",
    "\n",
    "\n",
    "import plotly.io as pio\n",
    "pio.renderers.default='browser'\n",
    "\n",
    "input_file = \"I:/My Drive/Research/gs_data/mov19_2022_03_03/2dgs_output/84444b22-6/point_cloud/iteration_1000/point_cloud.ply\"\n",
    "\n",
    "# input_file = \"I:/My Drive/Research/gs_data/mov19_2022_03_03/output/scaling_lr0.01_percent_dense0.01_densify_grad_threshold0.0002_position_lr_init1.6e-07/point_cloud/iteration_10/point_cloud.ply\"\n",
    "\n",
    "vertices = PlyData.read(input_file)[\"vertex\"]\n",
    "\n",
    "\n",
    "sh = np.column_stack([vertices[key] for key in vertices.data.dtype.names if 'rest' in key or 'dc' in key])\n",
    "rgb = sh_utils.rgb_from_sh(0,sh,xyz = None,camera_position = None)\n",
    "xyz = np.column_stack((vertices[\"x\"], vertices[\"y\"], vertices[\"z\"]))\n",
    "opacity = 1 / (1 + np.exp(-vertices[\"opacity\"]))#self.vertices[\"opacity\"]         \n",
    "\n",
    "# fig = go.Figure()\n",
    "# Plotters.scatter3d(fig,xyz[rgb[:,0]<1],rgb[rgb[:,1]<1],3)\n",
    "# fig.show()\n",
    "normalized_opacity = (opacity - opacity.min()) / (opacity.max() - opacity.min())\n",
    "cl = 0.4\n",
    "idx = (normalized_opacity > 0.5) & (rgb[:,0] < cl) & (rgb[:,0] > 0) & (rgb[:,1] < cl) & (rgb[:,1] > 0) & (rgb[:,2] < cl) & (rgb[:,2] > 0)\n",
    "vertices = vertices[idx]\n",
    "rgb = rgb[idx]\n",
    "normalized_opacity = normalized_opacity[idx]\n",
    "\n",
    "# Create the 3D scatter plot with hover template for color value\n",
    "\n",
    "fig = go.Figure()\n",
    "# Plotters.scatter3d(fig,frames['P1483CAM1.jpg'].points_in_ew_frame,'red',3,opa = 0.1)\n",
    "colors = [f'rgba({int(255*r)},{int(255*g)},{int(255*b)},1)' for r,g,b,a in np.column_stack((rgb,normalized_opacity))]\n",
    "hover_text = [f'color: {255*r},{255*g},{255*b},1' for r,g,b,a in np.column_stack((rgb,normalized_opacity))]\n",
    "\n",
    "\n",
    "\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=vertices[\"x\"],\n",
    "    y=vertices[\"y\"],\n",
    "    z=vertices[\"z\"],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=2,\n",
    "        color=colors,  # Color for each point \n",
    "        line_width=0,\n",
    "    ),\n",
    "    hovertext=hover_text,  # Show color as float\n",
    "\n",
    "))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_rotation(r):\n",
    "    norm = np.sqrt(r[:,0]*r[:,0] + r[:,1]*r[:,1] + r[:,2]*r[:,2] + r[:,3]*r[:,3])\n",
    "\n",
    "    q = r / norm[:, None]\n",
    "\n",
    "    R = np.zeros((q.shape[0], 3, 3))\n",
    "\n",
    "    r = q[:, 0]\n",
    "    x = q[:, 1]\n",
    "    y = q[:, 2]\n",
    "    z = q[:, 3]\n",
    "\n",
    "    R[:, 0, 0] = 1 - 2 * (y*y + z*z)\n",
    "    R[:, 0, 1] = 2 * (x*y - r*z)\n",
    "    R[:, 0, 2] = 2 * (x*z + r*y)\n",
    "    R[:, 1, 0] = 2 * (x*y + r*z)\n",
    "    R[:, 1, 1] = 1 - 2 * (x*x + z*z)\n",
    "    R[:, 1, 2] = 2 * (y*z - r*x)\n",
    "    R[:, 2, 0] = 2 * (x*z - r*y)\n",
    "    R[:, 2, 1] = 2 * (y*z + r*x)\n",
    "    R[:, 2, 2] = 1 - 2 * (x*x + y*y)\n",
    "    return R\n",
    "\n",
    "\n",
    "def build_scaling_rotation(s, r):\n",
    "    L = np.zeros((s.shape[0], 3, 3))\n",
    "    R = build_rotation(r)\n",
    "\n",
    "    L[:,0,0] = s[:,0]\n",
    "    L[:,1,1] = s[:,1]\n",
    "    L[:,2,2] = s[:,2]\n",
    "\n",
    "    L = R @ L\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(650, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = np.column_stack(([(vertices[f'scale_{idx}']) for idx in range(2)]))\n",
    "s = np.column_stack((s,vertices['scale_0']*0))\n",
    "s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def homogeneous(points):\n",
    "    \"\"\"\n",
    "    homogeneous points\n",
    "    :param points: [..., 3]\n",
    "    \"\"\"\n",
    "    return np.column_stack((points, np.ones(points.shape[0])))\n",
    "\n",
    "def homogeneous_vec(vec, vectoadd = [0,0,0]):\n",
    "    \"\"\"\n",
    "    homogeneous points\n",
    "    :param points: [..., 3]\n",
    "    \"\"\"\n",
    "    return np.concatenate((vec,np.tile(vectoadd,(650,1,1))),axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "means3d = np.column_stack((vertices['x'],vertices['y'],vertices['z']))\n",
    "viewmat = frames['P1483CAM1.jpg'].world_to_cam\n",
    "r = np.column_stack([(vertices[f'rot_{idx}']) for idx in range(4)])\n",
    "s = np.column_stack(([(vertices[f'scale_{idx}']) for idx in range(2)]))\n",
    "s = np.column_stack((s,vertices['scale_0']*0))\n",
    "rotations = build_scaling_rotation(s,r) # sutu, svtv (scale * axis direction in gaussian FoR)\n",
    "projmat = frames['P1483CAM1.jpg'].projection\n",
    "\n",
    "\n",
    "# 1. Viewing transform\n",
    "# Eq.4 and Eq.5\n",
    "p_view = (means3d @ viewmat[:3,:3]) + viewmat[-1:,:3] # rotate the gaussian mean to camera FoR\n",
    "uv_view = (rotations @ viewmat[:3,:3]) # rotate to camera FoR\n",
    "\n",
    "# M is H matrix that representes the transformation of the tangent plane. \n",
    "# its the scaled axes concatenated to the gaussian mean location - represented in homogeneous coordinates\n",
    "M = np.concatenate((homogeneous_vec(uv_view),homogeneous(p_view)[:,:,np.newaxis]),axis = 2)\n",
    "T = M @ projmat # T stands for (WH)^T in Eq.9\n",
    "distance = (temp_point * (T[..., 3] * T[..., 3])).sum(dim=-1, keepdims=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0102654 , -0.81995583, -0.56836435,  1.        ])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M[0,:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.99216820e-09,  6.10799897e-09,  4.25836293e-09,  0.00000000e+00])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T[0,:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Surface splatting (2D Gaussian Splatting)\n",
    "def setup(means3D, scales, quats, opacities, colors, viewmat, projmat):\n",
    "    rotations = build_scaling_rotation(scales, quats).permute(0,2,1)\n",
    "\n",
    "    # 1. Viewing transform\n",
    "    # Eq.4 and Eq.5\n",
    "    p_view = (means3D @ viewmat[:3,:3]) + viewmat[-1:,:3]\n",
    "    uv_view = (rotations @ viewmat[:3,:3])\n",
    "    M = torch.cat([homogeneous_vec(uv_view[:,:2,:]), homogeneous(p_view.unsqueeze(1))], dim=1)\n",
    "\n",
    "    T = M @ projmat # T stands for (WH)^T in Eq.9\n",
    "    # 2. Compute AABB\n",
    "    # Homogneous plane is very useful for both ray-splat intersection and bounding box computation\n",
    "    # we know how to compute u,v given x,y homogeneous plane already; computing AABB is done by a reverse process.\n",
    "    # i.e compute the x, y s.t. \\|hu^4\\| = 1 and \\|h_v^4\\|=1 (distance of gaussian center to plane in the uv space)\n",
    "    temp_point = torch.tensor([[1.,1., -1.]]).cuda()\n",
    "    distance = (temp_point * (T[..., 3] * T[..., 3])).sum(dim=-1, keepdims=True)\n",
    "    f = (1 / distance) * temp_point\n",
    "    point_image = torch.cat(\n",
    "        [(f * T[..., 0] * T[...,3]).sum(dim=-1, keepdims=True),\n",
    "        (f * T[..., 1] * T[...,3]).sum(dim=-1, keepdims=True),\n",
    "        (f * T[..., 2] * T[...,3]).sum(dim=-1, keepdims=True)], dim=-1)\n",
    "\n",
    "    half_extend = point_image * point_image - torch.cat(\n",
    "        [(f * T[..., 0] * T[...,0]).sum(dim=-1, keepdims=True),\n",
    "        (f * T[..., 1] * T[...,1]).sum(dim=-1, keepdims=True),\n",
    "        (f * T[..., 2] * T[...,2]).sum(dim=-1, keepdims=True)], dim=-1)\n",
    "\n",
    "    radii = half_extend.clamp(min=1e-4).sqrt() * 3 # three sigma\n",
    "    center = point_image\n",
    "\n",
    "    # 3. Perform Sorting\n",
    "    depth = p_view[..., 2] # depth is used only for sorting\n",
    "    index = depth.sort()[1]\n",
    "    T = T[index]\n",
    "    colors = colors[index]\n",
    "    center = center[index]\n",
    "    depth = depth[index]\n",
    "    radii = radii[index]\n",
    "    opacities = opacities[index]\n",
    "    return T, colors, opacities, center, depth, radii\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2DGS - Math explained\n",
    "### Modeling: \n",
    "The 2D Gaussian is defined in terms of its local coordinate system, where the $ X$ and $ Y$ axes are scaled according to the Gaussian's shape. The Gaussian is represented in the **world coordinates**, with the **axes** of the Gaussian in world space defined by the tangential vectors $ \\mathbf{t_u} $ and $ \\mathbf{t_v} $, and its **scaling factors** by $ s_u $ and $ s_v $. These tangential vectors define the directions of the local coordinate axes in the tangent plane (the object FoR).\n",
    "\n",
    "The **object plane**, which is the tangent plane to the Gaussian in world space, can be described using the plane equation:\n",
    "$$\n",
    "P(u, v) = p_k + s_u \\mathbf{t_u} u + s_v \\mathbf{t_v} v\n",
    "$$\n",
    "where $ p_k $ is the center of the Gaussian in world coordinates, and $ u $ and $ v $ represent local coordinates on the tangent plane. This equation expresses the position of any point in the tangent plane in terms of the world coordinates, as modified by the scaling along the tangential axes $ \\mathbf{t_u} $ and $ \\mathbf{t_v} $.\n",
    "\n",
    "To transform the local coordinates in the tangent plane (object frame of reference) to world coordinates, we define the following transformation matrix $ H $, which encodes the **scaling**, **rotation**, and **translation** from the object space to the world space:\n",
    "$$\n",
    "H = \\begin{pmatrix}\n",
    "s_u \\mathbf{t_u} & s_v \\mathbf{t_v} & 0 & p_k \\\\\n",
    "0 & 0 & 0 & 1\n",
    "\\end{pmatrix}\n",
    "= \\begin{pmatrix}\n",
    "R & p_k \\\\\n",
    "0 & 1\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "where:\n",
    "- $ \\mathbf{t_u} = \\begin{pmatrix} t_{u_x} \\\\ t_{u_y} \\\\ t_{u_z} \\end{pmatrix} $ and $ \\mathbf{t_v} = \\begin{pmatrix} t_{v_x} \\\\ t_{v_y} \\\\ t_{v_z} \\end{pmatrix} $ are the 3D tangential vectors (defining the axes of the tangent plane in world coordinates),\n",
    "- $ p_k = \\begin{pmatrix} p_{k_x} \\\\ p_{k_y} \\\\ p_{k_z} \\end{pmatrix} $ is the 3D position of the Gaussian center in world coordinates, and\n",
    "- $ R $ is the 3x3 rotation matrix that describes the orientation of the tangent plane in world space.\n",
    "\n",
    "The matrix $ H $ can be interpreted in two parts:\n",
    "- The first part, $ \\begin{pmatrix} s_u \\mathbf{t_u} & s_v \\mathbf{t_v} & 0 \\end{pmatrix} $, represents the scaling and rotation of the axes in the world coordinates. It scales the tangential vectors $ \\mathbf{t_u} $ and $ \\mathbf{t_v} $ by $ s_u $ and $ s_v $, respectively, and applies any rotational transformation.\n",
    "- The second part, $ p_k $, represents the **translation** of the Gaussian's center in world coordinates, which shifts the origin of the local tangent plane to the desired world position.\n",
    "\n",
    "The matrix can also be interpreted in terms of the rotation matrix $ R $ (which describes the orientation of the tangent plane in world space) and the translation vector $ p_k $. The transformation from local coordinates $ (u, v) $ to world coordinates $ (x, y, z) $ is thus achieved through the multiplication of $ H $ by the local coordinate vector:\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "x \\\\\n",
    "y \\\\\n",
    "z \\\\\n",
    "1\n",
    "\\end{pmatrix}\n",
    "= H \\begin{pmatrix}\n",
    "u \\\\\n",
    "v \\\\\n",
    "1 \\\\\n",
    "1\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "This transformation allows us to map a point in the tangent plane (object space) to the corresponding point in the world space, accounting for both the Gaussian's shape (through the scaling $ s_u, s_v $) and its orientation (through the rotation $ R $).\n",
    "\n",
    "In summary, the matrix $ H $ serves as a **homogeneous transformation** that encapsulates both the geometric properties (scaling and rotation) and the positioning (translation) of the 2D Gaussian in world space.\n",
    "\n",
    "for every u,v on the tangent plane we can calculate the gaussian power: \n",
    "$$ G(u) = \\exp\\left( -\\frac{u^2 + v^2}{2} \\right) \\tag{6} $$\n",
    "\n",
    "* $ \\mathbf{t_u} $ , $ \\mathbf{t_v} , $ $\\mathbf{s_u} $ and $\\mathbf{s_v}$ are learnable parameters.\n",
    "* each gaussian is defined by the opacity $\\alpha$ and a view dependent color.\n",
    "\n",
    "### Splatting\n",
    "\n",
    "\n",
    "The goal of this process is to find the intersection between a ray, originating from a pixel in the image, and the tangent plane of a 2D Gaussian, and then evaluate the power of the Gaussian at the intersection point. Below are the detailed steps.\n",
    "\n",
    "Step 1: Defining the Image Ray \n",
    "\n",
    "We begin by defining the ray from a pixel in the image using two orthogonal planes. The pixel location $(x, y) $ in the image space can be used to define two planes:\n",
    "\n",
    "\n",
    "* The x-plane (yz): a plane defined by a normal vector $ \\mathbf{n}_x = (-1, 0, 0) $ and an offset $ x $. The 4D homogeneous form is $ h_x = (-1, 0, 0, x) $.\n",
    "* The y-plane (xz): a plane defined by a normal vector $ \\mathbf{n}_y = (0, -1, 0) $ and an offset $ y $. The 4D homogeneous form is $ h_y = (0, -1, 0, y) $.\n",
    "\n",
    "\n",
    "These planes intersect at a ray in 3D space that is represented as the line of intersection between the two planes.\n",
    "\n",
    "Step 2: Transforming the Planes to the Tangent Plane\n",
    "\n",
    "Next, we transform the planes from the image space into the local coordinates of the 2D Gaussian primitive (the tangent plane). Using the transformation matrix $ M = (WH)^{-1} $, we apply the inverse transpose to the planes:\n",
    "\n",
    "$$\n",
    "h_u = (WH)^\\top h_x \\\\\n",
    "h_v = (WH)^\\top h_y\n",
    "$$\n",
    "\n",
    "Where $ W $ is the camera transformation matrix and $ H $ is the transformation matrix from the tangent plane to the world coordinates.\n",
    "\n",
    "Step 3: Solving for the Intersection\n",
    "\n",
    "The next step is to solve for the intersection point $(u, v) $ of the ray with the transformed tangent plane. We do this by solving the following system of equations:\n",
    "\n",
    "$$\n",
    "h_u \\cdot (u, v, 1, 1)^\\top = 0 \\\\\n",
    "h_v \\cdot (u, v, 1, 1)^\\top = 0\n",
    "$$\n",
    "\n",
    "Expanding these equations gives us:\n",
    "\n",
    "\n",
    "$$\n",
    "    h_1^u u + h_2^u v + h_3^u + h_4^u = 0 \\\\\n",
    "    h_1^v u + h_2^v v + h_3^v + h_4^v = 0\n",
    "$$\n",
    "\n",
    "\n",
    "The solution for $ u $ and $ v $ is obtained by solving this system of equations. This leads to the following expressions for the coordinates $ u(x) $ and $ v(x) $:\n",
    "\n",
    "$$\n",
    "u = \\frac{h_2^u h_4^v - h_4^u h_2^v}{h_1^u h_2^v - h_2^u h_1^v} \\\\\n",
    "v = \\frac{h_4^u h_1^v - h_1^u h_4^v}{h_1^u h_2^v - h_2^u h_1^v}\n",
    "$$\n",
    "\n",
    "Where $ h_i^u $ and $ h_i^v $ are the homogeneous parameters of the transformed planes.\n",
    "\n",
    "Step 4: Evaluating the Gaussian at the Intersection\n",
    "\n",
    "Once we have the coordinates $ (u, v) $, we can evaluate the 2D Gaussian function at the intersection point. The Gaussian function is typically of the form:\n",
    "\n",
    "$$\n",
    "G(u, v) = \\exp\\left( -\\frac{u^2 + v^2}{2} \\right)\n",
    "$$\n",
    "\n",
    "This represents the Gaussian value at the point $ (u, v) $ on the tangent plane.\n",
    "\n",
    "\n",
    "Once the values of $ u(x) $ and $ v(x) $ are found, we can compute the depth of the intersection point using the following equation:\n",
    "$$\n",
    "x = (x_z, y_z, z, z)^\\top = W P(u, v) = W H (u, v, 1, 1)^\\top\n",
    "$$\n",
    "Here, $ W $ is the camera projection matrix, and $ H $ is the transformation matrix from the tangent plane to world coordinates. The last component of the resulting vector $ x = (xz, yz, z, z)^\\top $ gives the depth $ z $ of the intersection point (the third element, need to make sure). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
