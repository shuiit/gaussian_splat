{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.insert(0, parent_dir)\n",
    "\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd().split('render')[0],'gaussian_data'))\n",
    "sys.path.insert(0, parent_dir)\n",
    "\n",
    "from gaussian_data.Camera import Camera\n",
    "from gaussian_data.Frame import Frame\n",
    "import gaussian_data.Plotters\n",
    "import gaussian_data.Utils as Utils\n",
    "\n",
    "from GaussianSplat import GaussianSplat\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from plyfile import PlyData\n",
    "import numpy as np\n",
    "import argparse\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "import Plotters\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "import scipy.io\n",
    "import pandas as pd\n",
    "from Render import Render\n",
    "\n",
    "%matplotlib qt\n",
    "\n",
    "# load hull\n",
    "path = 'G:/My Drive/Research/gs_data/mov19_2022_03_03/'\n",
    "real_coord = scipy.io.loadmat(f'{path}/3d_pts/real_coord.mat')['all_coords']\n",
    "points_3d = {body_wing : pd.DataFrame(Utils.load_hull(body_wing,path),columns = ['X','Y','Z','frame']) for body_wing in ['body','rwing','lwing']}\n",
    "# initilize objects\n",
    "frames = [1408]#list(range(500,700,13))\n",
    "\n",
    "image_names,points_in_idx = Utils.define_frames(frames,points_3d)\n",
    "cameras = {f'cam{cam + 1}':Camera(path,cam) for cam in range(4)}\n",
    "frames = {f'{im_name}.jpg':Frame(path,im_name,points_in_idx[im_name.split('CAM')[0]],real_coord,idx) for idx,im_name in enumerate(image_names)}\n",
    "# map 3d voxels to 2d pixels\n",
    "[frames[im_name].map_3d_2d(croped_image = True) for im_name in frames.keys()]\n",
    "voxel_dict,colors_dict = Utils.get_dict_for_points3d(frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load gaussian splatting output\n",
    "input_file = \"G:/My Drive/Research/gs_data/mov19_2022_03_03/output/frame140845_scaling_lr0.005_percent_dense0.0001_densify_grad_threshold0.0002_position_lr_init12/point_cloud/iteration_60000/point_cloud.ply\"\n",
    "# input_file = \"D:\\Documents/2dgs_output/point_cloud3.ply\"\n",
    "input_file = \"G:/My Drive/Research/gs_data/mov19_2022_03_03/time/time2_norm01_dist1000000_iter200_start100_moreFr/1408/point_cloud/iteration_200/point_cloud.ply\"\n",
    "# input_file = \"G:/My Drive/Research/gs_data/mov19_2022_03_03/2dgs_output/93701c9b-c2/point_cloud/iteration_1000/point_cloud.ply\"\n",
    "\n",
    "gs = GaussianSplat(input_file)  \n",
    "gs.save_gs('_2dsplat')\n",
    "# reproject and filter background\n",
    "gs_filtered = gs.filter(gs.projection_filter(frames,gs.xyz,croped_image = True),path = gs.path)\n",
    "gs_filtered.save_gs('_filtered')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = frames[f'{image_names[2]}.jpg'].get_croped_camera()\n",
    "render = Render(gs,cam,tiles = [1,10],block_xy = [16,16], image_size = [160,160],gaus3d = False,filtersze = np.sqrt(2) / 2)\n",
    "\n",
    "image = render.render_image()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Figure size 640x480 with 1 Axes>,\n",
       " <matplotlib.image.AxesImage at 0x2982aebdc00>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure(),plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.00112268, 0.00112602, ..., 0.28472146, 0.28472418,\n",
       "       1.        ])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# render image \n",
    "image_name = f'{image_names[0]}.jpg'\n",
    "\n",
    "cam1 = frames[image_name].get_croped_camera()\n",
    "cam4 = frames[f'{image_names[0]}.jpg'].get_croped_camera()\n",
    "\n",
    "rotmat = np.array([[1,0,0],[0,1,0],[0,0,1]])\n",
    "\n",
    "K_crop = cam4.K\n",
    "K_crop[0,0] = K_crop[0,0]\n",
    "K_crop[1,1] = K_crop[1,1]\n",
    "\n",
    "R = rotmat @ cam4.R\n",
    "X0 = cam4.X0 + np.array([[0,0,0]]).T\n",
    "cam = Camera(cam1.path,5,cam = {'camera': np.hstack((K_crop,R,X0))[:, :, np.newaxis]},image_size = [160,160])\n",
    "\n",
    "cam = frames[f'{image_names[0]}.jpg'].get_croped_camera()\n",
    "\n",
    "\n",
    "\n",
    "render = Render(gs,cam,tiles = [1,10],block_xy = [16,16], image_size = [160,160])\n",
    "image = render.render_image()\n",
    "plt.figure(),plt.imshow(image)\n",
    "# plt.figure(),plt.imshow(render.depth)\n",
    "np.unique(render.depth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Camera' object has no attribute 'K_crop'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mK_crop\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Camera' object has no attribute 'K_crop'"
     ]
    }
   ],
   "source": [
    "cam.K_crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1fbe5a8bc40>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.imshow(np.mean(image,2)*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['P1408CAM1.jpg', 'P1408CAM2.jpg', 'P1408CAM3.jpg', 'P1408CAM4.jpg'])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f587a063e0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.imshow(np.array(frames['P1408CAM3.jpg'].croped_image) - np.mean(image,2)*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sh_utils\n",
    "\n",
    "vertices = PlyData.read(input_file)[\"vertex\"]\n",
    "\n",
    "\n",
    "sh = np.column_stack([vertices[key] for key in vertices.data.dtype.names if 'rest' in key or 'dc' in key])\n",
    "rgb = sh_utils.rgb_from_sh(0,sh,xyz = None,camera_position = None)\n",
    "xyz = np.column_stack((vertices[\"x\"], vertices[\"y\"], vertices[\"z\"]))\n",
    "\n",
    "[frames[im_name].map_3d_2d(croped_image = True, use_zbuff = True) for im_name in frames.keys()]\n",
    "fig = go.Figure()\n",
    "color_pts = ['red','green','blue','black']\n",
    "fig = go.Figure()\n",
    "im_name = list(frames.keys())[0]\n",
    "for cam in range(4):\n",
    "    image = f'{im_name.split(\"CAM\")[0]}CAM{cam+1}.jpg'\n",
    "    Plotters.scatter3d(fig,frames[image].voxels_with_idx,color_pts[cam],3)\n",
    "opacity = 1 / (1 + np.exp(-vertices[\"opacity\"]))   \n",
    "\n",
    "vertices = vertices[(rgb[:,0] < 0.9) & (rgb[:,0] > 0) & (opacity > 0.1) & (rgb[:,2] < 0.9) & (rgb[:,2] > 0) & (rgb[:,1] < 0.9) & (rgb[:,1] > 0)]\n",
    "rgb = rgb[(rgb[:,0] < 0.9) & (rgb[:,0] > 0) & (opacity > 0.1) & (rgb[:,2] < 0.9) & (rgb[:,2] > 0) & (rgb[:,1] < 0.9) & (rgb[:,1] > 0)]\n",
    "\n",
    "# Create the 3D scatter plot with hover template for color value\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=vertices[\"x\"],\n",
    "    y=vertices[\"y\"],\n",
    "    z=vertices[\"z\"],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=3,\n",
    "        color=rgb[:,0],  # Color for each point\n",
    "        colorscale='Gray',  # Choose a colorscale\n",
    "        opacity=0.5,  # Use the opacity per point\n",
    "        colorbar=dict(title=\"Colorbar\")  # Optional colorbar\n",
    "    ),\n",
    "    hovertemplate='Color: %{marker.color:.4f}<extra></extra>',  # Show color as float\n",
    "))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_rotation(r):\n",
    "    norm = np.sqrt(r[:,0]*r[:,0] + r[:,1]*r[:,1] + r[:,2]*r[:,2] + r[:,3]*r[:,3])\n",
    "\n",
    "    q = r / norm[:, None]\n",
    "\n",
    "    R = np.zeros((q.shape[0], 3, 3))\n",
    "\n",
    "    r = q[:, 0]\n",
    "    x = q[:, 1]\n",
    "    y = q[:, 2]\n",
    "    z = q[:, 3]\n",
    "\n",
    "    R[:, 0, 0] = 1 - 2 * (y*y + z*z)\n",
    "    R[:, 0, 1] = 2 * (x*y - r*z)\n",
    "    R[:, 0, 2] = 2 * (x*z + r*y)\n",
    "    R[:, 1, 0] = 2 * (x*y + r*z)\n",
    "    R[:, 1, 1] = 1 - 2 * (x*x + z*z)\n",
    "    R[:, 1, 2] = 2 * (y*z - r*x)\n",
    "    R[:, 2, 0] = 2 * (x*z - r*y)\n",
    "    R[:, 2, 1] = 2 * (y*z + r*x)\n",
    "    R[:, 2, 2] = 1 - 2 * (x*x + y*y)\n",
    "    return R\n",
    "def build_scaling_rotation(s, r):\n",
    "    L = np.zeros((s.shape[0], 3, 3))\n",
    "    R = build_rotation(r)\n",
    "\n",
    "    L[:,0,0] = s[:,0]\n",
    "    L[:,1,1] = s[:,1]\n",
    "    L[:,2,2] = s[:,2]\n",
    "\n",
    "    L = R @ L\n",
    "    return L\n",
    "\n",
    "def intersection_point(pixel,T):\n",
    "    k = -T[..., 0] + pixel[0]*T[...,3]\n",
    "    l = -T[..., 1] + pixel[1] * T[..., 3]\n",
    "    points = np.cross(k, l, axis=-1)\n",
    "    return points[..., :2] / points[..., -1:]\n",
    "\n",
    "def homogeneous(points):\n",
    "    \"\"\"\n",
    "    homogeneous points\n",
    "    :param points: [..., 3]\n",
    "    \"\"\"\n",
    "    return np.column_stack((points, np.ones(points.shape[0])))\n",
    "\n",
    "def homogeneous_vec(vec, vectoadd = [0,0]):\n",
    "    \"\"\"\n",
    "    homogeneous points\n",
    "    :param points: [..., 3]\n",
    "    \"\"\"\n",
    "    return np.concatenate((vec,np.tile(np.array([vectoadd]).T,(vec.shape[0],1,1))),axis = 2)\n",
    "\n",
    "\n",
    "# Surface splatting (2D Gaussian Splatting)\n",
    "def setup(means3D, scales, quats, opacities, colors, viewmat, projmat):\n",
    "    rotations = build_scaling_rotation(scales, quats)\n",
    "\n",
    "   \n",
    "    # 1. Viewing transform\n",
    "    # Eq.4 and Eq.5\n",
    "    p_view = (means3D @ viewmat[:3,:3]) + viewmat[-1:,:3] # rotate the gaussian mean to camera FoR\n",
    "    uv_view = (rotations @ viewmat[:3,:3]) # rotate to camera FoR\n",
    "\n",
    "    # M is H matrix that representes the transformation from tangent plane to camera. \n",
    "    # its the scaled axes concatenated to the gaussian mean location - represented in homogeneous coordinates\n",
    "\n",
    "    # !! need to check that the order of axes ar ok for M !!\n",
    "    M = np.concatenate((homogeneous_vec(uv_view[:,:2,:]),homogeneous(p_view)[:,np.newaxis]),axis = 1)\n",
    "    T = M @ projmat # T stands for (WH)^T in Eq.9 - projmat transforms from camera to NDC (screen coordinates)\n",
    "    # T is the transformation of every gaussian from tangent plane to NDC, its homogebnus coordinates. with the rotation matrix \n",
    "    # representing the axes and the translation vector representing the location of the center of each gaussian. \n",
    "    # We notice that projmat is a prespective projection matrix. \n",
    "\n",
    "    # Next, We calculate the radius of the gaussian. We normalize by w to get homogeneus coordinates. In addition we flip Z axis (not sure why) \n",
    "    # we calculate the distance from the camera to the gaussian mean (this is w, the last row of a homogenues coordinate, deviding by it will give perspective view)\n",
    "    # Notice that the rotation is scaled (in build_scaling_rotation) and is not normalized.\n",
    "\n",
    "    # point_image - the projectes mean of the gaussian (with flipped z)\n",
    "    # half_extend - used to calculate the radius of the gaussian, we take 3 sigma. because the ratation is scaled \n",
    "    # we calculate the distance for each axis and can get the 3 sigma by multiplying each distance. (we also devide by w to get the prespective view)\n",
    "\n",
    "    temp_point = np.tile([1,1,-1],(T.shape[0],1))\n",
    "    distance  = np.sum(temp_point*T[..., 3] * T[..., 3],-1)\n",
    "    f = (1 / distance[:,np.newaxis]) * temp_point\n",
    "\n",
    "    # distance = (temp_point * (T[..., 3] * T[..., 3])).sum(dim=-1, keepdims=True)\n",
    "    point_image = np.column_stack((np.sum(f * T[..., 0] * T[...,3],1),np.sum(f * T[..., 1] * T[...,3],1),np.sum(f * T[..., 2] * T[...,3],1)))\n",
    "\n",
    "    axes_dist = np.column_stack((np.sum(f * T[..., 0] * T[...,0],1),np.sum(f * T[..., 1] * T[...,1],1),np.sum(f * T[..., 2] * T[...,2],1)))\n",
    "\n",
    "    half_extend = point_image * point_image - axes_dist\n",
    "    radii = np.sqrt(np.maximum(half_extend, 1e-4)) * 3\n",
    "    center = point_image\n",
    "\n",
    "    # 3. Perform Sorting\n",
    "    depth = p_view[..., 2] # depth is used only for sorting\n",
    "    index = np.argsort(depth)\n",
    "    T = T[index]\n",
    "    colors = colors[index]\n",
    "    center = center[index]\n",
    "    depth = depth[index]\n",
    "    radii = radii[index]\n",
    "    return T, colors, opacities, center, depth, radii\n",
    "\n",
    "\n",
    "\n",
    "intrins = frames['P1408CAM1.jpg'].K_crop\n",
    "projmat = np.zeros((4,4))\n",
    "projmat[:3,:3] = intrins\n",
    "projmat[-1,-2] = 1.0\n",
    "projmat = projmat.T\n",
    "viewmat = frames['P1408CAM1.jpg'].world_to_cam.T\n",
    "T, colors, opacities, center, depth, radii = setup(gs.xyz, gs.scale, gs.rot, gs.opacity, gs.color, viewmat, projmat)\n",
    "\n",
    "# # Rasterization\n",
    "# # 1. Generate pixels\n",
    "# W, H = 80,160#int(intrins[0, -1] * 2), int(intrins[1, -1] * 2)\n",
    "# pix_x, pix_y = np.meshgrid(np.arange(W), np.arange(H), indexing='xy')\n",
    "# pix = np.stack([pix_x, pix_y], axis=-1)\n",
    "\n",
    "# # 2. Compute ray splat intersection # Eq.9 and Eq.10\n",
    "# pix_flat = pix.reshape(-1, 1, 2)\n",
    "# pixels = np.squeeze(pix_flat)\n",
    "# x,y = pixels[:,0],pixels[:,1]\n",
    "# s = np.vstack([intersection_point(pixel,T) for pixel in pixels])\n",
    "\n",
    "\n",
    "# # 3. Add \n",
    "# # -pass filter # Eq.11\n",
    "# # When a point (2D Gaussian) is viewed from a far distance or at a slanted angle,\n",
    "# # the 2D Gaussian falls between pixels, and no fragment is used to rasterize the Gaussian.\n",
    "# # Add a low-pass filter to handle aliasing.\n",
    "# dist3d = np.sum(s * s, axis=-1)\n",
    "# dist3d = np.reshape(dist3d,(len(pixels),T.shape[0]))\n",
    "\n",
    "# filtersze = np.sqrt(2) / 2\n",
    "# dist_xycenter = np.hstack([pixel - center[None, :, :2] for pixel in pixels])\n",
    "# dist2d = (1 / filtersze) ** 2 * np.linalg.norm(dist_xycenter, axis=-1) ** 2\n",
    "# dist2d = np.reshape(dist2d,(len(pixels),T.shape[0]))\n",
    "# # Min of dist2 is equal to max of Gaussian exp(-0.5 * dist2)\n",
    "# dist2 = np.minimum(dist3d, dist2d)\n",
    "\n",
    "# depth_acc = np.sum(homogeneous(s)*np.tile(T[..., -1],(len(pixels),1)),axis = 1)\n",
    "# depth_acc = np.reshape(depth_acc,(len(pixels),T.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.06498141e-05, 7.69689944e-05, 1.60000000e-06],\n",
       "       [7.98608723e-05, 8.76289931e-05, 1.60000000e-06],\n",
       "       [8.31628697e-05, 9.40807091e-05, 1.60000000e-06],\n",
       "       ...,\n",
       "       [9.92269857e-05, 8.62566106e-05, 1.60000000e-06],\n",
       "       [8.34508671e-05, 5.89549979e-05, 1.60000000e-06],\n",
       "       [7.89204542e-05, 8.14726523e-05, 1.60000000e-06]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'T' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m cam \u001b[38;5;241m=\u001b[39m frames[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_names[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mget_croped_camera()\n\u001b[1;32m----> 2\u001b[0m render \u001b[38;5;241m=\u001b[39m Render(gs,cam,tiles \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m10\u001b[39m],block_xy \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m16\u001b[39m,\u001b[38;5;241m16\u001b[39m], image_size \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m160\u001b[39m,\u001b[38;5;241m160\u001b[39m],T \u001b[38;5;241m=\u001b[39m \u001b[43mT\u001b[49m,center \u001b[38;5;241m=\u001b[39m center,gaus3d \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m image \u001b[38;5;241m=\u001b[39m render\u001b[38;5;241m.\u001b[39mrender_image()\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(),plt\u001b[38;5;241m.\u001b[39mimshow(image)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'T' is not defined"
     ]
    }
   ],
   "source": [
    "cam = frames[f'{image_names[0]}.jpg'].get_croped_camera()\n",
    "render = Render(gs,cam,tiles = [1,10],block_xy = [16,16], image_size = [160,160],T = T,center = center,gaus3d = True)\n",
    "\n",
    "image = render.render_image()\n",
    "plt.figure(),plt.imshow(image)\n",
    "# plt.figure(),plt.imshow(render.depth)\n",
    "np.unique(render.depth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# projection\n",
    "xyz = np.column_stack((vertices[\"x\"], vertices[\"y\"], vertices[\"z\"]))\n",
    "\n",
    "im_name= 'P1408CAM1.jpg'\n",
    "fig,axs = plt.subplots(2,2)\n",
    "for cam in range(4):\n",
    "    cam_obj  = frames[f'{image_names[cam]}.jpg'].get_croped_camera()\n",
    "\n",
    "    image = f'{im_name.split(\"CAM\")[0]}CAM{cam+1}.jpg'\n",
    "    homo_voxels_with_idx = frames[image].add_homo_coords(xyz)\n",
    "    proj = cam_obj.project_with_proj_mat(xyz)\n",
    "    axs[cam // 2,cam % 2].imshow(frames[image].croped_image)\n",
    "    axs[cam // 2,cam % 2].scatter(proj[:,0],proj[:,1],s = 3,c = rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elliptical Gaussian (from EWA article) - Math explained\n",
    "\n",
    "\n",
    "we define an elliptical gaussian: \n",
    "\n",
    "Equation 1: $G_\\mathbf{V}(\\mathbf{x} - \\mathbf{p}) = \\frac{1}{2 \\pi |\\mathbf{V}|} \\frac{1}{2} e^{-\\frac{1}{2} (\\mathbf{x} - \\mathbf{p})^T \\mathbf{V}^{-1} (\\mathbf{x} - \\mathbf{p})}.$\n",
    "\n",
    "* $V$ is the covariance matrix\n",
    "* $\\mathbf{x}$ - a 3d coordinate (in gaussian axes)\n",
    "* $\\mathbf{p}$ - the mean of the gaussian \n",
    "### Affine projection of the gauusian\n",
    "We define an arbitrary affine mapping from object space $ \\mathbf{u} = \\Phi(\\mathbf{x}) $, where $ \\Phi(\\mathbf{x}) = \\mathbf{Mx + c} $, \n",
    "\n",
    "and we substitute $ \\mathbf{x} = \\Phi^{-1}(\\mathbf{u}) $. Since $ \\Phi^{-1}(\\mathbf{u}) = \\mathbf{M}^{-1}(\\mathbf{u} - \\mathbf{c}) $, we get:\n",
    "\n",
    "$$\n",
    "G_\\mathbf{V}(\\Phi^{-1}(\\mathbf{u}) - \\mathbf{p}) = \n",
    "\\frac{1}{|M^{-1}|} \\cdot \\frac{1}{(2 \\pi)^{3/2} |\\mathbf{V}|^{1/2}} e^{-\\frac{1}{2} (\\mathbf{M}^{-1}(\\mathbf{u} - \\mathbf{c}) - \\mathbf{p})^T \\mathbf{V}^{-1} (\\mathbf{M}^{-1}(\\mathbf{u} - \\mathbf{c}) - \\mathbf{p})} = \n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{1}{|M^{-1}|} \\cdot \\frac{1}{(2 \\pi)^{3/2} |\\mathbf{V}|^{1/2}} e^{-\\frac{1}{2} (\\mathbf{u} - \\mathbf{c} - \\mathbf{Mp})^T \\mathbf{M}^{-1} \\mathbf{V}^{-1} (\\mathbf{M}^{-1})^T (\\mathbf{u} - \\mathbf{c} - \\mathbf{Mp})} = \n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{1}{|M^{-1}|} \\cdot \\frac{1}{(2 \\pi)^{3/2} |\\mathbf{V}|^{1/2}} e^{-\\frac{1}{2} (\\mathbf{u} - \\Phi(\\mathbf{p}))^T (\\mathbf{MVM}^T)^{-1} (\\mathbf{u} - \\Phi(\\mathbf{p}))}.\n",
    "$$\n",
    "\n",
    "from this, to ease the writing we define equation 2: \n",
    "\n",
    "Equation 2: $G \\mathbf{V}(\\Phi^{-1}(u) - \\mathbf{p}) = \\frac{1}{|\\mathbf{M}^{-1}|} G_{ \\mathbf{M} \\mathbf{V} \\mathbf{M}^T} (u - \\Phi(\\mathbf{p})).$\n",
    "\n",
    "#### The covariance matrix\n",
    "$V$, the covariance matrix is a symetrix matrix that can be ragarded as a transformation. it scales and shears the data (thus defining the orientation and ratio between the gaussian principal axes). \n",
    "As mentioned above, the gaussian is transformed using an affine mapping $\\Phi(X)$. Usually we use this kind of mapping to transform a vector or a 3D point to a new FoR (change basis). Because the covariance matrix is a transformation, in order to change its FoR (basis), we will perform $\\mathbf{V_{1}} = MVM^{T}$. We first multiply $VM^{T}$  - transform (whatever xyz we multiply) from camera to body ($M^{T}$) and then multiply by $V$ which is in object coordinates - now we have coordinates in object basis after shear and scale. we then multiply by $M$ again to transform back to camera coordinates. \n",
    "\n",
    "\n",
    "### Projection\n",
    "\n",
    "\n",
    "![alt text](ray_ewa.png)\n",
    "#### Ray space\n",
    "\n",
    "We converted to camera space, now we want to convert to ray space. The coordinates in ray space are defined such that $x_0, x_1$ are the coordinates on the image plane and the devision by $u_2$ adds prespective. $u_3$ is then defined as the euclidean distance from the point to the origin (camera). \n",
    "\n",
    "\n",
    "$$ \\text{ray space to camera: }\n",
    "\\begin{pmatrix}\n",
    "x_0 \\\\\n",
    "x_1 \\\\\n",
    "x_2 \\\\\n",
    "\n",
    "\\end{pmatrix} = m(u) = \\begin{pmatrix}\n",
    "u_0 / u_2 \\\\\n",
    "u_1/u_2 \\\\\n",
    "||(u_0, u_1, u_2)||^{T} \\\\\n",
    "\\end{pmatrix}\n",
    "\n",
    "\\text{,camera to ray space: }\n",
    "\\begin{pmatrix}\n",
    "u_0 \\\\\n",
    "u_1 \\\\\n",
    "u_2 \\\\\n",
    "\n",
    "\\end{pmatrix} = m^{-1}(x) = \\begin{pmatrix}\n",
    "x_0/||(x_0,x_1,1)^T|| \\cdot x_2 \\\\\n",
    "x_1/||(x_0,x_1,1)^T|| \\cdot x_2 \\\\\n",
    "1/||(x_0,x_1,1)^T|| \\cdot x_2 \\\\\n",
    "\n",
    "\\end{pmatrix}\n",
    "\n",
    "\n",
    "$$\n",
    "  \n",
    "Ray space is defined with 3 coordinates $(x_0,x_1,x_2)$ where $x_0$ and $x_1$ represents the location of the pixel and $x_3$ is the euclidean distance from the camera origin to $(x_1,x_2). This transformation is not affine due to the devision by $u_2$, parallel lines are not preserved and the shape of the gaussian will be distorted. (in addition, the dimention is problematic).\n",
    "In order to solve this a local affine approximation $\\mathbf{m_{u_k}}$ of the projection transformation is defined. The approximation is the first to terms of the Tayor expansion of $\\mathbf{m}$ at point $\\mathbf{u}_{k}$:\n",
    "$$\\mathbf{m_{u_k}\\mathbf(u)} = \\mathbf x_k+\\mathbf J_{\\mathbf{u}_k}\\cdot ( \\mathbf u-\\mathbf u_k )$$\n",
    "where $\\mathbf x_k=\\mathbf m(\\mathbf u_k)$ is the mean of the gaussian in ray space (can be transformed using the mapping m, the projection matrix) and the Jacobian $ J_{u_k} = \\frac{\\partial m}{\\partial u}(u_k) $\n",
    "\n",
    "### The gaussian mapping\n",
    "#### Object to camera coordinates (as detailed in Affine projection of the gauusian)\n",
    "\n",
    "The reconstruction kernels are initially given in object space, which has coordinates $t =(t_0,t_1,t_2)^T$ . \n",
    "* Gaussian reconstruction kernels in object space: $r\"_k (t)=G_{V\"_k} (t − t_k)$, where $t_k$ are the voxel positions in object space\n",
    "* Object coordinates are transformed to camera coordinates using an affine mapping $\\mathbf u = \\phi(t)$, called viewing transformation. It is defined by a matrix $\\mathbf W$ and a translation vector $\\mathbf d$ as $\\phi(t) = Wt + d$. We transform the reconstruction kernels $G_{V\"k} (t − t_k)$ to camera space by substituting $t = \\phi ^{−1}(u)$ and using Equation 2 : \n",
    "\n",
    "$G \\mathbf{V\"_{k}}(\\Phi^{-1}(u) - t_k) = \\frac{1}{|\\mathbf{W}^{-1}|} G_{V'_k } (\\mathbf u - \\mathbf u_k) = r'_k(u\\mathbf).$\n",
    "\n",
    "where $u_k = \\phi(\\mathbf t_k)$ is the center of the Gaussian in camera coordinates and $r′_k(\\mathbf u)$ denotes the reconstruction kernel in camera space. According to equation 2, the covariance matrix in camera coordinates $V′_k$ is given by $V′_k = WV\"_kW^T$ (exactly as detailed in Affine projection of the gauusian).\n",
    "\n",
    "#### Camera to ray space\n",
    "Reminder: the local affine transformation - $$\\mathbf{m_{u_k}\\mathbf(u)} = \\mathbf x_k+\\mathbf J_{\\mathbf{u}_k}\\cdot ( \\mathbf u-\\mathbf u_k )$$\n",
    "$\\mathbf{m_{u_k}\\mathbf(u)}$ transforms from camera to ray, hence $x_k=m(u_k)$ where $x_k$ is the center of the gaussian in ray space. \n",
    "since $\\mathbf x = m(\\mathbf u)$ we get that $ u = \\mathbf m^{-1}(\\mathbf(x))$ hence: \n",
    "$$ u = \\mathbf m^{-1}(x) = \\mathbf(x - x_k)\\cdot \\mathbf J^{-1}_{\\mathbf u_k} + \\mathbf u_k $$\n",
    "$$ r_k(\\mathbf x) = \\frac{1}{|\\mathbf W^{-1}|}\\cdot G_{\\mathbf V'_k}(\\mathbf{(x - x_k)\\cdot J^{-1}_{\\mathbf u_k} + \\mathbf u_k - \\mathbf u_k}) = \\\\\n",
    "\\frac{1}{|\\mathbf W^{-1}||\\mathbf J^{-1}|}G_{\\mathbf V'_k}(J^{-1}_{\\mathbf u_k}\\mathbf{(x - x_k)})\\\\$$\n",
    "\n",
    "and the new covariance matrix is defined:  $Vk = JV'_{k}$ $J^T = JWV\"_kW^TJ^T$.\n",
    "where V\"_k is the original covariance matrix\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Perspective Projection and Jacobian Derivation\n",
    "\n",
    "In a pinhole camera model, the perspective projection of a 3D point \\((X, Y, Z)\\) into 2D image coordinates \\((x, y)\\) can be expressed as:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "x \\\\\n",
    "y \\\\\n",
    "1\n",
    "\\end{bmatrix} = \\frac{1}{Z} \\cdot\n",
    "\\begin{bmatrix}\n",
    "f_x \\cdot X + c_x \\cdot Z \\\\\n",
    "f_y \\cdot Y + c_y \\cdot Z \\\\\n",
    "Z\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "* $(x, y)$  : are the projected 2D coordinates on the image plane.\n",
    "* $(X, Y, Z)$  : are the coordinates in the 3D space. \n",
    "* $f_x , f_y$  : are the focal lengths in the x and y directions, respectively. \n",
    "* $c_x , c_y$  : are the coordinates of the principal point (optical center) in the image. \n",
    "\n",
    "### Derivation of the Jacobian\n",
    "\n",
    "To derive the Jacobian, we compute the partial derivatives of the projected 2D coordinates \\((x, y)\\) with respect to the 3D coordinates \\((X, Y, Z)\\).\n",
    "\n",
    "1. **From the perspective projection equations**:\n",
    "   - For \\(x\\):\n",
    "   $$\n",
    "   x = \\frac{f_x \\cdot X + c_x \\cdot Z}{Z}\n",
    "   $$\n",
    "   - For \\(y\\):\n",
    "   $$\n",
    "   y = \\frac{f_y \\cdot Y + c_y \\cdot Z}{Z}\n",
    "   $$\n",
    "\n",
    "2. **Calculating the derivatives**:\n",
    "   - The derivatives with respect to \\(Z\\) yield:\n",
    "     - For \\(x\\):\n",
    "     $$\n",
    "     \\frac{\\partial x}{\\partial X} = \\frac{f_x}{Z}, \\quad \\frac{\\partial x}{\\partial Y} = 0, \\quad \\frac{\\partial x}{\\partial Z} = -\\frac{f_x \\cdot X}{Z^2}\n",
    "     $$\n",
    "     - For \\(y\\):\n",
    "     $$\n",
    "     \\frac{\\partial y}{\\partial X} = 0, \\quad \\frac{\\partial y}{\\partial Y} = \\frac{f_y}{Z}, \\quad \\frac{\\partial y}{\\partial Z} = -\\frac{f_y \\cdot Y}{Z^2}\n",
    "     $$\n",
    "\n",
    "3. **Forming the Jacobian**:\n",
    "   Using the derivatives calculated above, the Jacobian matrix \\(J\\) becomes:\n",
    "   $$\n",
    "   J = \\begin{bmatrix}\n",
    "   \\frac{f_x}{Z} & 0 & -\\frac{f_x \\cdot X}{Z^2} \\\\\n",
    "   0 & \\frac{f_y}{Z} & -\\frac{f_y \\cdot Y}{Z^2}\n",
    "   \\end{bmatrix}\n",
    "   $$\n",
    "\n",
    "\n",
    "### 2D Projection \n",
    "We calculate the conics coeffitient for each gaussian : $$Ax^2+Bxy+Cy^2 = 0$$, where $A = \\frac{\\sigma_y^2}{|V|}$, $B = \\frac{\\sigma_xy}{|V|}$ and  $C = \\frac{\\sigma_x^2}{|V|}$\n",
    "we then multiply by the distace between the gaussiam and the pixel. this is the same as: \n",
    "$-\\frac{1}{2} (\\mathbf{x} - \\mathbf{p})^T \\mathbf{V}^{-1} (\\mathbf{x} - \\mathbf{p})$ - the exponent of the gaussian\n",
    "\n",
    "wIncorporating the scaled conic, which represents the 2D Gaussian as an ellipse in the Gaussian equation, we can express the effect of every Gaussian on the pixel's color as follows:\n",
    "\n",
    "$$\n",
    "G_{\\mathbf{V}}(\\mathbf{x}) = \\frac{1}{(2\\pi)^{3/2} |\\mathbf{V}|^{1/2}} e^{-\\frac{1}{2} ( Ax^2+Bxy+Cy^2)}\n",
    "$$\n",
    "\n",
    "This equation captures how each Gaussian contributes to the pixel's color based on its distance from the pixel and the shape defined by the covariance matrix.\n",
    "\n",
    "## tiles\n",
    "To render the image we devide it to tiles of $ 16 X 16 $, for each tile we sort the gaussians according to the distance from the camera. we then sample all gaussians effect per pixel in the tile (using the power equation to calculate the opacity). We sum the gaussians color values and multiply by the opacity (doing alpha blending, each time we update the opacity according to the already calculated gaussians $color = RGB * \\alpha *\\alpha_{blend})$ were for eacg gaussian we add we update $\\alpha_{blend} =  \\alpha_{blend}*(1-\\alpha) $ (when we reach 0, its opaque). to later do the alpha blend we pick for each tile only the gaussians that intersect with the tile. since gaussians are not bounded, we bound them with 3 $\\sigma_x$ and 3 $\\sigma_y$ bounding box in each axis. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
