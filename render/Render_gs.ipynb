{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.insert(0, parent_dir)\n",
    "\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd().split('render')[0],'gaussian_data'))\n",
    "sys.path.insert(0, parent_dir)\n",
    "\n",
    "from gaussian_data.Camera import Camera\n",
    "from gaussian_data.Frame import Frame\n",
    "import gaussian_data.Plotters\n",
    "import gaussian_data.Utils as Utils\n",
    "\n",
    "from GaussianSplat import GaussianSplat\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from plyfile import PlyData\n",
    "import numpy as np\n",
    "import argparse\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "import Plotters\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "import scipy.io\n",
    "import pandas as pd\n",
    "from Render import Render\n",
    "\n",
    "%matplotlib qt\n",
    "\n",
    "# load hull\n",
    "path = 'G:/My Drive/Research/gs_data/mov19_2022_03_03/'\n",
    "real_coord = scipy.io.loadmat(f'{path}/3d_pts/real_coord.mat')['all_coords']\n",
    "points_3d = {body_wing : pd.DataFrame(Utils.load_hull(body_wing,path),columns = ['X','Y','Z','frame']) for body_wing in ['body','rwing','lwing']}\n",
    "# initilize objects\n",
    "frames = [1407]#list(range(500,700,13))\n",
    "\n",
    "image_names,points_in_idx = Utils.define_frames(frames,points_3d)\n",
    "cameras = {f'cam{cam + 1}':Camera(path,cam) for cam in range(4)}\n",
    "frames = {f'{im_name}.jpg':Frame(path,im_name,points_in_idx[im_name.split('CAM')[0]],real_coord,idx) for idx,im_name in enumerate(image_names)}\n",
    "# map 3d voxels to 2d pixels\n",
    "[frames[im_name].map_3d_2d(croped_image = True) for im_name in frames.keys()]\n",
    "voxel_dict,colors_dict = Utils.get_dict_for_points3d(frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load gaussian splatting output\n",
    "input_file = \"G:/My Drive/Research/gs_data/mov19_2022_03_03/output/frame140845_scaling_lr0.005_percent_dense0.0001_densify_grad_threshold0.0002_position_lr_init12/point_cloud/iteration_60000/point_cloud.ply\"\n",
    "# input_file = \"D:\\Documents/2dgs_output/point_cloud3.ply\"\n",
    "input_file = \"G:/My Drive/Research/gs_data/mov19_2022_03_03/time/time2_norm01_dist1000000_iter200_start100_moreFr/1419/point_cloud/iteration_200/point_cloud.ply\"\n",
    "input_file = \"G:/My Drive/Research/gs_data/mov19_2022_03_03/time/ln02ld10itr2000far02lr005_2/1407/point_cloud/iteration_1000/point_cloud.ply\"\n",
    "# input_file = \"G:/My Drive/Research/gs_data/mov19_2022_03_03/time/wakk80001/1425/point_cloud/iteration_1400/point_cloud.ply\"\n",
    "\n",
    "\n",
    "# input_file = \"G:/My Drive/Research/gs_data/mov19_2022_03_03/2dgs_output/93701c9b-c2/point_cloud/iteration_1000/point_cloud.ply\"\n",
    "\n",
    "gs = GaussianSplat(input_file)  \n",
    "gs.save_gs('_2dsplat')\n",
    "# reproject and filter background\n",
    "gs_filtered = gs.filter(gs.projection_filter(frames,gs.xyz,croped_image = True),path = gs.path)\n",
    "gs_filtered.save_gs('_filtered')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sh_utils\n",
    "\n",
    "vertices = PlyData.read(input_file)[\"vertex\"]\n",
    "vertices = gs_filtered.xyz\n",
    "\n",
    "# sh = np.column_stack([vertices[key] for key in vertices.data.dtype.names if 'rest' in key or 'dc' in key])\n",
    "# rgb = sh_utils.rgb_from_sh(0,sh,xyz = None,camera_position = None)\n",
    "# xyz = np.column_stack((vertices[\"x\"], vertices[\"y\"], vertices[\"z\"]))\n",
    "\n",
    "\n",
    "sh = gs_filtered.sh\n",
    "rgb = gs_filtered.color\n",
    "xyz = gs_filtered.xyz\n",
    "opacity = gs_filtered.opacity\n",
    "\n",
    "[frames[im_name].map_3d_2d(croped_image = True, use_zbuff = True) for im_name in frames.keys()]\n",
    "fig = go.Figure()\n",
    "color_pts = ['red','green','blue','black']\n",
    "fig = go.Figure()\n",
    "im_name = list(frames.keys())[0]\n",
    "for cam in range(4):\n",
    "    image = f'{im_name.split(\"CAM\")[0]}CAM{cam+1}.jpg'\n",
    "    Plotters.scatter3d(fig,frames[image].voxels_with_idx,color_pts[cam],3)\n",
    "opacity = 1 / (1 + np.exp(-opacity))   \n",
    "\n",
    "vertices = vertices[(rgb[:,0] < 0.9) & (rgb[:,0] > 0) & (opacity > 0.1) & (rgb[:,2] < 0.9) & (rgb[:,2] > 0) & (rgb[:,1] < 0.9) & (rgb[:,1] > 0)]\n",
    "rgb = rgb[(rgb[:,0] < 0.9) & (rgb[:,0] > 0) & (opacity > 0.1) & (rgb[:,2] < 0.9) & (rgb[:,2] > 0) & (rgb[:,1] < 0.9) & (rgb[:,1] > 0)]\n",
    "\n",
    "# Create the 3D scatter plot with hover template for color value\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=xyz[:,0],\n",
    "    y=xyz[:,1],\n",
    "    z=xyz[:,2],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=3,\n",
    "        color=rgb[:,0],  # Color for each point\n",
    "        colorscale='Gray',  # Choose a colorscale\n",
    "        opacity=0.5,  # Use the opacity per point\n",
    "        colorbar=dict(title=\"Colorbar\")  # Optional colorbar\n",
    "    ),\n",
    "    hovertemplate='Color: %{marker.color:.4f}<extra></extra>',  # Show color as float\n",
    "))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Figure size 640x480 with 1 Axes>,\n",
       " <matplotlib.image.AxesImage at 0x2952bfa3940>)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cam = frames[f'{image_names[3]}.jpg'].get_croped_camera()\n",
    "render = Render(gs,cam,tiles = [1,10],block_xy = [16,16], image_size = [160,160],gaus3d = False,filtersze = 0.5)\n",
    "\n",
    "image = render.render_image()\n",
    "plt.figure(),plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Figure size 640x480 with 1 Axes>,\n",
       " <matplotlib.image.AxesImage at 0x2952a2399f0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure(),plt.imshow(render.distortion)\n",
    "plt.figure(),plt.imshow(render.depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'm' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 22\u001b[0m\n\u001b[0;32m     17\u001b[0m cam \u001b[38;5;241m=\u001b[39m frames[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_names[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mget_croped_camera()\n\u001b[0;32m     21\u001b[0m render \u001b[38;5;241m=\u001b[39m Render(gs,cam,tiles \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m10\u001b[39m],block_xy \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m16\u001b[39m,\u001b[38;5;241m16\u001b[39m], image_size \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m160\u001b[39m,\u001b[38;5;241m160\u001b[39m])\n\u001b[1;32m---> 22\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mrender\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(),plt\u001b[38;5;241m.\u001b[39mimshow(image)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# plt.figure(),plt.imshow(render.depth)\u001b[39;00m\n",
      "File \u001b[1;32md:\\Documents\\gaussian_splat\\render\\Render.py:127\u001b[0m, in \u001b[0;36mRender.render_image\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrender_image\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;124;03m    Renders the final image by iterating over each tile and calculating pixel values.\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \n\u001b[0;32m    124\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;124;03m        np.array: The rendered image as a 3D numpy array (height, width, color channels).\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 127\u001b[0m     [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalc_pixels_value_in_tile(tile) \u001b[38;5;28;01mfor\u001b[39;00m tile \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtiles]\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrendered_image\n",
      "File \u001b[1;32md:\\Documents\\gaussian_splat\\render\\Render.py:127\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrender_image\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;124;03m    Renders the final image by iterating over each tile and calculating pixel values.\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \n\u001b[0;32m    124\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;124;03m        np.array: The rendered image as a 3D numpy array (height, width, color channels).\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 127\u001b[0m     [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalc_pixels_value_in_tile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtile\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m tile \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtiles]\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrendered_image\n",
      "File \u001b[1;32md:\\Documents\\gaussian_splat\\render\\Render.py:142\u001b[0m, in \u001b[0;36mRender.calc_pixels_value_in_tile\u001b[1;34m(self, tile)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtiles[tile][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprojection\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m pixel \u001b[38;5;129;01min\u001b[39;00m pixels_in_tile:\n\u001b[1;32m--> 142\u001b[0m         pixel_value,temp_alpha,depth,distortion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalc_pixel_value\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtiles\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtile\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpixel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    143\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrendered_image[pixel[\u001b[38;5;241m1\u001b[39m],pixel[\u001b[38;5;241m0\u001b[39m]] \u001b[38;5;241m=\u001b[39m pixel_value \u001b[38;5;241m+\u001b[39m temp_alpha\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m    144\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdepth[pixel[\u001b[38;5;241m1\u001b[39m],pixel[\u001b[38;5;241m0\u001b[39m]] \u001b[38;5;241m=\u001b[39m depth \n",
      "File \u001b[1;32md:\\Documents\\gaussian_splat\\render\\Render.py:101\u001b[0m, in \u001b[0;36mRender.calc_pixel_value\u001b[1;34m(self, tile_params, pixel)\u001b[0m\n\u001b[0;32m     99\u001b[0m image,T \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msum_all_gs_in_tile(alpha[idx_to_keep],tile_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolor\u001b[39m\u001b[38;5;124m'\u001b[39m][idx_to_keep])\n\u001b[0;32m    100\u001b[0m depth,T \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msum_all_gs_in_tile(alpha[idx_to_keep],tile_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcam_coord\u001b[39m\u001b[38;5;124m'\u001b[39m][idx_to_keep,\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m--> 101\u001b[0m distortion,T \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msum_all_depth_in_tile(alpha[idx_to_keep],\u001b[43mm\u001b[49m[idx_to_keep])\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(distortion) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    103\u001b[0m     wakk \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'm' referenced before assignment"
     ]
    }
   ],
   "source": [
    "# render image \n",
    "image_name = f'{image_names[0]}.jpg'\n",
    "\n",
    "cam1 = frames[image_name].get_croped_camera()\n",
    "cam4 = frames[f'{image_names[0]}.jpg'].get_croped_camera()\n",
    "\n",
    "rotmat = np.array([[1,0,0],[0,1,0],[0,0,1]])\n",
    "\n",
    "K_crop = cam4.K\n",
    "K_crop[0,0] = K_crop[0,0]\n",
    "K_crop[1,1] = K_crop[1,1]\n",
    "\n",
    "R = rotmat @ cam4.R\n",
    "X0 = cam4.X0 + np.array([[0,0,0]]).T\n",
    "cam = Camera(cam1.path,5,cam = {'camera': np.hstack((K_crop,R,X0))[:, :, np.newaxis]},image_size = [160,160])\n",
    "\n",
    "cam = frames[f'{image_names[0]}.jpg'].get_croped_camera()\n",
    "\n",
    "\n",
    "\n",
    "render = Render(gs,cam,tiles = [1,10],block_xy = [16,16], image_size = [160,160])\n",
    "image = render.render_image()\n",
    "plt.figure(),plt.imshow(image)\n",
    "# plt.figure(),plt.imshow(render.depth)\n",
    "np.unique(render.depth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.06498141e-05, 7.69689944e-05, 1.60000000e-06],\n",
       "       [7.98608723e-05, 8.76289931e-05, 1.60000000e-06],\n",
       "       [8.31628697e-05, 9.40807091e-05, 1.60000000e-06],\n",
       "       ...,\n",
       "       [9.92269857e-05, 8.62566106e-05, 1.60000000e-06],\n",
       "       [8.34508671e-05, 5.89549979e-05, 1.60000000e-06],\n",
       "       [7.89204542e-05, 8.14726523e-05, 1.60000000e-06]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'T' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m cam \u001b[38;5;241m=\u001b[39m frames[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_names[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mget_croped_camera()\n\u001b[1;32m----> 2\u001b[0m render \u001b[38;5;241m=\u001b[39m Render(gs,cam,tiles \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m10\u001b[39m],block_xy \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m16\u001b[39m,\u001b[38;5;241m16\u001b[39m], image_size \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m160\u001b[39m,\u001b[38;5;241m160\u001b[39m],T \u001b[38;5;241m=\u001b[39m \u001b[43mT\u001b[49m,center \u001b[38;5;241m=\u001b[39m center,gaus3d \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m image \u001b[38;5;241m=\u001b[39m render\u001b[38;5;241m.\u001b[39mrender_image()\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(),plt\u001b[38;5;241m.\u001b[39mimshow(image)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'T' is not defined"
     ]
    }
   ],
   "source": [
    "cam = frames[f'{image_names[0]}.jpg'].get_croped_camera()\n",
    "render = Render(gs,cam,tiles = [1,10],block_xy = [16,16], image_size = [160,160],T = T,center = center,gaus3d = True)\n",
    "\n",
    "image = render.render_image()\n",
    "plt.figure(),plt.imshow(image)\n",
    "# plt.figure(),plt.imshow(render.depth)\n",
    "np.unique(render.depth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# projection\n",
    "xyz = np.column_stack((vertices[\"x\"], vertices[\"y\"], vertices[\"z\"]))\n",
    "\n",
    "im_name= 'P1408CAM1.jpg'\n",
    "fig,axs = plt.subplots(2,2)\n",
    "for cam in range(4):\n",
    "    cam_obj  = frames[f'{image_names[cam]}.jpg'].get_croped_camera()\n",
    "\n",
    "    image = f'{im_name.split(\"CAM\")[0]}CAM{cam+1}.jpg'\n",
    "    homo_voxels_with_idx = frames[image].add_homo_coords(xyz)\n",
    "    proj = cam_obj.project_with_proj_mat(xyz)\n",
    "    axs[cam // 2,cam % 2].imshow(frames[image].croped_image)\n",
    "    axs[cam // 2,cam % 2].scatter(proj[:,0],proj[:,1],s = 3,c = rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elliptical Gaussian (from EWA article) - Math explained\n",
    "\n",
    "\n",
    "we define an elliptical gaussian: \n",
    "\n",
    "Equation 1: $G_\\mathbf{V}(\\mathbf{x} - \\mathbf{p}) = \\frac{1}{2 \\pi |\\mathbf{V}|} \\frac{1}{2} e^{-\\frac{1}{2} (\\mathbf{x} - \\mathbf{p})^T \\mathbf{V}^{-1} (\\mathbf{x} - \\mathbf{p})}.$\n",
    "\n",
    "* $V$ is the covariance matrix\n",
    "* $\\mathbf{x}$ - a 3d coordinate (in gaussian axes)\n",
    "* $\\mathbf{p}$ - the mean of the gaussian \n",
    "### Affine projection of the gauusian\n",
    "We define an arbitrary affine mapping from object space $ \\mathbf{u} = \\Phi(\\mathbf{x}) $, where $ \\Phi(\\mathbf{x}) = \\mathbf{Mx + c} $, \n",
    "\n",
    "and we substitute $ \\mathbf{x} = \\Phi^{-1}(\\mathbf{u}) $. Since $ \\Phi^{-1}(\\mathbf{u}) = \\mathbf{M}^{-1}(\\mathbf{u} - \\mathbf{c}) $, we get:\n",
    "\n",
    "$$\n",
    "G_\\mathbf{V}(\\Phi^{-1}(\\mathbf{u}) - \\mathbf{p}) = \n",
    "\\frac{1}{|M^{-1}|} \\cdot \\frac{1}{(2 \\pi)^{3/2} |\\mathbf{V}|^{1/2}} e^{-\\frac{1}{2} (\\mathbf{M}^{-1}(\\mathbf{u} - \\mathbf{c}) - \\mathbf{p})^T \\mathbf{V}^{-1} (\\mathbf{M}^{-1}(\\mathbf{u} - \\mathbf{c}) - \\mathbf{p})} = \n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{1}{|M^{-1}|} \\cdot \\frac{1}{(2 \\pi)^{3/2} |\\mathbf{V}|^{1/2}} e^{-\\frac{1}{2} (\\mathbf{u} - \\mathbf{c} - \\mathbf{Mp})^T \\mathbf{M}^{-1} \\mathbf{V}^{-1} (\\mathbf{M}^{-1})^T (\\mathbf{u} - \\mathbf{c} - \\mathbf{Mp})} = \n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{1}{|M^{-1}|} \\cdot \\frac{1}{(2 \\pi)^{3/2} |\\mathbf{V}|^{1/2}} e^{-\\frac{1}{2} (\\mathbf{u} - \\Phi(\\mathbf{p}))^T (\\mathbf{MVM}^T)^{-1} (\\mathbf{u} - \\Phi(\\mathbf{p}))}.\n",
    "$$\n",
    "\n",
    "from this, to ease the writing we define equation 2: \n",
    "\n",
    "Equation 2: $G \\mathbf{V}(\\Phi^{-1}(u) - \\mathbf{p}) = \\frac{1}{|\\mathbf{M}^{-1}|} G_{ \\mathbf{M} \\mathbf{V} \\mathbf{M}^T} (u - \\Phi(\\mathbf{p})).$\n",
    "\n",
    "#### The covariance matrix\n",
    "$V$, the covariance matrix is a symetrix matrix that can be ragarded as a transformation. it scales and shears the data (thus defining the orientation and ratio between the gaussian principal axes). \n",
    "As mentioned above, the gaussian is transformed using an affine mapping $\\Phi(X)$. Usually we use this kind of mapping to transform a vector or a 3D point to a new FoR (change basis). Because the covariance matrix is a transformation, in order to change its FoR (basis), we will perform $\\mathbf{V_{1}} = MVM^{T}$. We first multiply $VM^{T}$  - transform (whatever xyz we multiply) from camera to body ($M^{T}$) and then multiply by $V$ which is in object coordinates - now we have coordinates in object basis after shear and scale. we then multiply by $M$ again to transform back to camera coordinates. \n",
    "\n",
    "\n",
    "### Projection\n",
    "\n",
    "\n",
    "![alt text](ray_ewa.png)\n",
    "#### Ray space\n",
    "\n",
    "We converted to camera space, now we want to convert to ray space. The coordinates in ray space are defined such that $x_0, x_1$ are the coordinates on the image plane and the devision by $u_2$ adds prespective. $u_3$ is then defined as the euclidean distance from the point to the origin (camera). \n",
    "\n",
    "\n",
    "$$ \\text{ray space to camera: }\n",
    "\\begin{pmatrix}\n",
    "x_0 \\\\\n",
    "x_1 \\\\\n",
    "x_2 \\\\\n",
    "\n",
    "\\end{pmatrix} = m(u) = \\begin{pmatrix}\n",
    "u_0 / u_2 \\\\\n",
    "u_1/u_2 \\\\\n",
    "||(u_0, u_1, u_2)||^{T} \\\\\n",
    "\\end{pmatrix}\n",
    "\n",
    "\\text{,camera to ray space: }\n",
    "\\begin{pmatrix}\n",
    "u_0 \\\\\n",
    "u_1 \\\\\n",
    "u_2 \\\\\n",
    "\n",
    "\\end{pmatrix} = m^{-1}(x) = \\begin{pmatrix}\n",
    "x_0/||(x_0,x_1,1)^T|| \\cdot x_2 \\\\\n",
    "x_1/||(x_0,x_1,1)^T|| \\cdot x_2 \\\\\n",
    "1/||(x_0,x_1,1)^T|| \\cdot x_2 \\\\\n",
    "\n",
    "\\end{pmatrix}\n",
    "\n",
    "\n",
    "$$\n",
    "  \n",
    "Ray space is defined with 3 coordinates $(x_0,x_1,x_2)$ where $x_0$ and $x_1$ represents the location of the pixel and $x_3$ is the euclidean distance from the camera origin to $(x_1,x_2). This transformation is not affine due to the devision by $u_2$, parallel lines are not preserved and the shape of the gaussian will be distorted. (in addition, the dimention is problematic).\n",
    "In order to solve this a local affine approximation $\\mathbf{m_{u_k}}$ of the projection transformation is defined. The approximation is the first to terms of the Tayor expansion of $\\mathbf{m}$ at point $\\mathbf{u}_{k}$:\n",
    "$$\\mathbf{m_{u_k}\\mathbf(u)} = \\mathbf x_k+\\mathbf J_{\\mathbf{u}_k}\\cdot ( \\mathbf u-\\mathbf u_k )$$\n",
    "where $\\mathbf x_k=\\mathbf m(\\mathbf u_k)$ is the mean of the gaussian in ray space (can be transformed using the mapping m, the projection matrix) and the Jacobian $ J_{u_k} = \\frac{\\partial m}{\\partial u}(u_k) $\n",
    "\n",
    "### The gaussian mapping\n",
    "#### Object to camera coordinates (as detailed in Affine projection of the gauusian)\n",
    "\n",
    "The reconstruction kernels are initially given in object space, which has coordinates $t =(t_0,t_1,t_2)^T$ . \n",
    "* Gaussian reconstruction kernels in object space: $r\"_k (t)=G_{V\"_k} (t − t_k)$, where $t_k$ are the voxel positions in object space\n",
    "* Object coordinates are transformed to camera coordinates using an affine mapping $\\mathbf u = \\phi(t)$, called viewing transformation. It is defined by a matrix $\\mathbf W$ and a translation vector $\\mathbf d$ as $\\phi(t) = Wt + d$. We transform the reconstruction kernels $G_{V\"k} (t − t_k)$ to camera space by substituting $t = \\phi ^{−1}(u)$ and using Equation 2 : \n",
    "\n",
    "$G \\mathbf{V\"_{k}}(\\Phi^{-1}(u) - t_k) = \\frac{1}{|\\mathbf{W}^{-1}|} G_{V'_k } (\\mathbf u - \\mathbf u_k) = r'_k(u\\mathbf).$\n",
    "\n",
    "where $u_k = \\phi(\\mathbf t_k)$ is the center of the Gaussian in camera coordinates and $r′_k(\\mathbf u)$ denotes the reconstruction kernel in camera space. According to equation 2, the covariance matrix in camera coordinates $V′_k$ is given by $V′_k = WV\"_kW^T$ (exactly as detailed in Affine projection of the gauusian).\n",
    "\n",
    "#### Camera to ray space\n",
    "Reminder: the local affine transformation - $$\\mathbf{m_{u_k}\\mathbf(u)} = \\mathbf x_k+\\mathbf J_{\\mathbf{u}_k}\\cdot ( \\mathbf u-\\mathbf u_k )$$\n",
    "$\\mathbf{m_{u_k}\\mathbf(u)}$ transforms from camera to ray, hence $x_k=m(u_k)$ where $x_k$ is the center of the gaussian in ray space. \n",
    "since $\\mathbf x = m(\\mathbf u)$ we get that $ u = \\mathbf m^{-1}(\\mathbf(x))$ hence: \n",
    "$$ u = \\mathbf m^{-1}(x) = \\mathbf(x - x_k)\\cdot \\mathbf J^{-1}_{\\mathbf u_k} + \\mathbf u_k $$\n",
    "$$ r_k(\\mathbf x) = \\frac{1}{|\\mathbf W^{-1}|}\\cdot G_{\\mathbf V'_k}(\\mathbf{(x - x_k)\\cdot J^{-1}_{\\mathbf u_k} + \\mathbf u_k - \\mathbf u_k}) = \\\\\n",
    "\\frac{1}{|\\mathbf W^{-1}||\\mathbf J^{-1}|}G_{\\mathbf V'_k}(J^{-1}_{\\mathbf u_k}\\mathbf{(x - x_k)})\\\\$$\n",
    "\n",
    "and the new covariance matrix is defined:  $Vk = JV'_{k}$ $J^T = JWV\"_kW^TJ^T$.\n",
    "where V\"_k is the original covariance matrix\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Perspective Projection and Jacobian Derivation\n",
    "\n",
    "In a pinhole camera model, the perspective projection of a 3D point \\((X, Y, Z)\\) into 2D image coordinates \\((x, y)\\) can be expressed as:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "x \\\\\n",
    "y \\\\\n",
    "1\n",
    "\\end{bmatrix} = \\frac{1}{Z} \\cdot\n",
    "\\begin{bmatrix}\n",
    "f_x \\cdot X + c_x \\cdot Z \\\\\n",
    "f_y \\cdot Y + c_y \\cdot Z \\\\\n",
    "Z\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "* $(x, y)$  : are the projected 2D coordinates on the image plane.\n",
    "* $(X, Y, Z)$  : are the coordinates in the 3D space. \n",
    "* $f_x , f_y$  : are the focal lengths in the x and y directions, respectively. \n",
    "* $c_x , c_y$  : are the coordinates of the principal point (optical center) in the image. \n",
    "\n",
    "### Derivation of the Jacobian\n",
    "\n",
    "To derive the Jacobian, we compute the partial derivatives of the projected 2D coordinates \\((x, y)\\) with respect to the 3D coordinates \\((X, Y, Z)\\).\n",
    "\n",
    "1. **From the perspective projection equations**:\n",
    "   - For \\(x\\):\n",
    "   $$\n",
    "   x = \\frac{f_x \\cdot X + c_x \\cdot Z}{Z}\n",
    "   $$\n",
    "   - For \\(y\\):\n",
    "   $$\n",
    "   y = \\frac{f_y \\cdot Y + c_y \\cdot Z}{Z}\n",
    "   $$\n",
    "\n",
    "2. **Calculating the derivatives**:\n",
    "   - The derivatives with respect to \\(Z\\) yield:\n",
    "     - For \\(x\\):\n",
    "     $$\n",
    "     \\frac{\\partial x}{\\partial X} = \\frac{f_x}{Z}, \\quad \\frac{\\partial x}{\\partial Y} = 0, \\quad \\frac{\\partial x}{\\partial Z} = -\\frac{f_x \\cdot X}{Z^2}\n",
    "     $$\n",
    "     - For \\(y\\):\n",
    "     $$\n",
    "     \\frac{\\partial y}{\\partial X} = 0, \\quad \\frac{\\partial y}{\\partial Y} = \\frac{f_y}{Z}, \\quad \\frac{\\partial y}{\\partial Z} = -\\frac{f_y \\cdot Y}{Z^2}\n",
    "     $$\n",
    "\n",
    "3. **Forming the Jacobian**:\n",
    "   Using the derivatives calculated above, the Jacobian matrix \\(J\\) becomes:\n",
    "   $$\n",
    "   J = \\begin{bmatrix}\n",
    "   \\frac{f_x}{Z} & 0 & -\\frac{f_x \\cdot X}{Z^2} \\\\\n",
    "   0 & \\frac{f_y}{Z} & -\\frac{f_y \\cdot Y}{Z^2}\n",
    "   \\end{bmatrix}\n",
    "   $$\n",
    "\n",
    "\n",
    "### 2D Projection \n",
    "We calculate the conics coeffitient for each gaussian : $$Ax^2+Bxy+Cy^2 = 0$$, where $A = \\frac{\\sigma_y^2}{|V|}$, $B = \\frac{\\sigma_xy}{|V|}$ and  $C = \\frac{\\sigma_x^2}{|V|}$\n",
    "we then multiply by the distace between the gaussiam and the pixel. this is the same as: \n",
    "$-\\frac{1}{2} (\\mathbf{x} - \\mathbf{p})^T \\mathbf{V}^{-1} (\\mathbf{x} - \\mathbf{p})$ - the exponent of the gaussian\n",
    "\n",
    "wIncorporating the scaled conic, which represents the 2D Gaussian as an ellipse in the Gaussian equation, we can express the effect of every Gaussian on the pixel's color as follows:\n",
    "\n",
    "$$\n",
    "G_{\\mathbf{V}}(\\mathbf{x}) = \\frac{1}{(2\\pi)^{3/2} |\\mathbf{V}|^{1/2}} e^{-\\frac{1}{2} ( Ax^2+Bxy+Cy^2)}\n",
    "$$\n",
    "\n",
    "This equation captures how each Gaussian contributes to the pixel's color based on its distance from the pixel and the shape defined by the covariance matrix.\n",
    "\n",
    "## tiles\n",
    "To render the image we devide it to tiles of $ 16 X 16 $, for each tile we sort the gaussians according to the distance from the camera. we then sample all gaussians effect per pixel in the tile (using the power equation to calculate the opacity). We sum the gaussians color values and multiply by the opacity (doing alpha blending, each time we update the opacity according to the already calculated gaussians $color = RGB * \\alpha *\\alpha_{blend})$ were for eacg gaussian we add we update $\\alpha_{blend} =  \\alpha_{blend}*(1-\\alpha) $ (when we reach 0, its opaque). to later do the alpha blend we pick for each tile only the gaussians that intersect with the tile. since gaussians are not bounded, we bound them with 3 $\\sigma_x$ and 3 $\\sigma_y$ bounding box in each axis. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
