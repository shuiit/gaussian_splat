{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.insert(0, parent_dir)\n",
    "\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd().split('render')[0],'gaussian_data'))\n",
    "sys.path.insert(0, parent_dir)\n",
    "\n",
    "from gaussian_data.Camera import Camera\n",
    "from gaussian_data.Frame import Frame\n",
    "import gaussian_data.Plotters\n",
    "import gaussian_data.Utils as Utils\n",
    "\n",
    "from GaussianSplat import GaussianSplat\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from plyfile import PlyData\n",
    "import numpy as np\n",
    "import argparse\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "import Plotters\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "import scipy.io\n",
    "import pandas as pd\n",
    "from Render import Render\n",
    "\n",
    "%matplotlib qt\n",
    "\n",
    "# load hull\n",
    "path = 'G:/My Drive/Research/gs_data/mov19_2022_03_03/'\n",
    "real_coord = scipy.io.loadmat(f'{path}/3d_pts/real_coord.mat')['all_coords']\n",
    "points_3d = {body_wing : pd.DataFrame(Utils.load_hull(body_wing,path),columns = ['X','Y','Z','frame']) for body_wing in ['body','rwing','lwing']}\n",
    "# initilize objects\n",
    "frames = [1520]#list(range(500,700,13))\n",
    "\n",
    "image_names,points_in_idx = Utils.define_frames(frames,points_3d)\n",
    "cameras = {f'cam{cam + 1}':Camera(path,cam) for cam in range(4)}\n",
    "frames = {f'{im_name}.jpg':Frame(path,im_name,points_in_idx[im_name.split('CAM')[0]],real_coord,idx) for idx,im_name in enumerate(image_names)}\n",
    "# map 3d voxels to 2d pixels\n",
    "[frames[im_name].map_3d_2d(croped_image = True) for im_name in frames.keys()]\n",
    "voxel_dict,colors_dict = Utils.get_dict_for_points3d(frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "no field of name scale_2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m input_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mG:/My Drive/Research/gs_data/mov19_2022_03_03/output/scaling_lr0.005_percent_dense0.001_densify_grad_threshold0.0002_position_lr_init1.6e-07/point_cloud/iteration_30000/point_cloud.ply\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m input_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDocuments/2dgs_output/point_cloud3.ply\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 6\u001b[0m gs \u001b[38;5;241m=\u001b[39m \u001b[43mGaussianSplat\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_file\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# reproject and filter background\u001b[39;00m\n\u001b[0;32m      9\u001b[0m gs_filtered \u001b[38;5;241m=\u001b[39m gs\u001b[38;5;241m.\u001b[39mfilter(gs\u001b[38;5;241m.\u001b[39mprojection_filter(frames,gs\u001b[38;5;241m.\u001b[39mxyz,croped_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m),path \u001b[38;5;241m=\u001b[39m gs\u001b[38;5;241m.\u001b[39mpath)\n",
      "File \u001b[1;32md:\\Documents\\gaussian_splat\\render\\GaussianSplat.py:23\u001b[0m, in \u001b[0;36mGaussianSplat.__init__\u001b[1;34m(self, path, vertices, block_xy, image_size, sh)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvertices \u001b[38;5;241m=\u001b[39m PlyData\u001b[38;5;241m.\u001b[39mread(path)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvertex\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m vertices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m vertices\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mxyz \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcolumn_stack((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvertices[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvertices[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvertices[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexp(np\u001b[38;5;241m.\u001b[39mcolumn_stack(([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvertices[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscale_0\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvertices[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscale_1\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvertices\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscale_2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m])))\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopacity \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvertices[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopacity\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\u001b[38;5;66;03m#self.vertices[\"opacity\"]         \u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrot \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcolumn_stack([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvertices[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrot_0\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvertices[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrot_1\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvertices[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrot_2\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvertices[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrot_3\u001b[39m\u001b[38;5;124m\"\u001b[39m]])\n",
      "File \u001b[1;32mc:\\Users\\Roni\\anaconda3\\lib\\site-packages\\plyfile.py:717\u001b[0m, in \u001b[0;36mPlyElement.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    713\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m    714\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    715\u001b[0m \u001b[38;5;124;03m    Proxy to `self.data.__getitem__` for convenience.\u001b[39;00m\n\u001b[0;32m    716\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 717\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Roni\\anaconda3\\lib\\site-packages\\numpy\\core\\memmap.py:334\u001b[0m, in \u001b[0;36mmemmap.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[1;32m--> 334\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(res) \u001b[38;5;129;01mis\u001b[39;00m memmap \u001b[38;5;129;01mand\u001b[39;00m res\u001b[38;5;241m.\u001b[39m_mmap \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    336\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39mndarray)\n",
      "\u001b[1;31mValueError\u001b[0m: no field of name scale_2"
     ]
    }
   ],
   "source": [
    "# load gaussian splatting output\n",
    "input_file = \"G:/My Drive/Research/gs_data/mov19_2022_03_03/output/scaling_lr0.005_percent_dense0.001_densify_grad_threshold0.0002_position_lr_init1.6e-07/point_cloud/iteration_30000/point_cloud.ply\"\n",
    "input_file = \"D:\\Documents/2dgs_output/point_cloud3.ply\"\n",
    "\n",
    "\n",
    "gs = GaussianSplat(input_file)  \n",
    "\n",
    "# reproject and filter background\n",
    "gs_filtered = gs.filter(gs.projection_filter(frames,gs.xyz,croped_image = True),path = gs.path)\n",
    "gs_filtered.save_gs()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2bdc1350040>,\n",
       " <matplotlib.lines.Line2D at 0x2bdc13500a0>,\n",
       " <matplotlib.lines.Line2D at 0x2bdc13500d0>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(rgb[rgb[:,0]<1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "memmap([0., 0., 0., ..., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sh_utils\n",
    "input_file = \"D:\\Documents/2dgs_output/point_cloud.ply\"\n",
    "\n",
    "vertices = PlyData.read(input_file)[\"vertex\"] \n",
    "sh = np.column_stack([vertices[key] for key in vertices.data.dtype.names if 'rest' in key or 'dc' in key])\n",
    "rgb = sh_utils.rgb_from_sh(0,sh,xyz = None,camera_position = None)\n",
    "xyz = np.column_stack((vertices[\"x\"], vertices[\"y\"], vertices[\"z\"]))\n",
    "fig = go.Figure()\n",
    "Plotters.scatter3d(fig,xyz[rgb[:,0]<1],rgb[rgb[:,0]<1],3)\n",
    "fig.show()\n",
    "\n",
    "plt.plot(vertices['nx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2bdc2cccdc0>]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(vertices['ny'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "(): incompatible function arguments. The following argument types are supported:\n    1. (self: open3d.cpu.pybind.geometry.PointCloud, arg0: open3d.cpu.pybind.utility.Vector3dVector) -> None\n\nInvoked with: PointCloud with 39211 points., array([[0., 0., 0.],\n       [0., 0., 0.],\n       [0., 0., 0.],\n       ...,\n       [0., 0., 0.],\n       [0., 0., 0.],\n       [0., 0., 0.]], dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 7\u001b[0m\n\u001b[0;32m      2\u001b[0m mesh \u001b[38;5;241m=\u001b[39m o3d\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mread_point_cloud(input_file) \u001b[38;5;66;03m# Read the point cloud\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Visualize the point cloud within open3d\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Visualize the point cloud with normals\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m mesh\u001b[38;5;241m.\u001b[39mnormals \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcolumn_stack((np\u001b[38;5;241m.\u001b[39marray(vertices[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnx\u001b[39m\u001b[38;5;124m'\u001b[39m]),np\u001b[38;5;241m.\u001b[39marray(vertices[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mny\u001b[39m\u001b[38;5;124m'\u001b[39m]),np\u001b[38;5;241m.\u001b[39marray(vertices[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnz\u001b[39m\u001b[38;5;124m'\u001b[39m])))\n\u001b[0;32m      8\u001b[0m o3d\u001b[38;5;241m.\u001b[39mvisualization\u001b[38;5;241m.\u001b[39mdraw_geometries([mesh], point_show_normal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: (): incompatible function arguments. The following argument types are supported:\n    1. (self: open3d.cpu.pybind.geometry.PointCloud, arg0: open3d.cpu.pybind.utility.Vector3dVector) -> None\n\nInvoked with: PointCloud with 39211 points., array([[0., 0., 0.],\n       [0., 0., 0.],\n       [0., 0., 0.],\n       ...,\n       [0., 0., 0.],\n       [0., 0., 0.],\n       [0., 0., 0.]], dtype=float32)"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "mesh = o3d.io.read_point_cloud(input_file) # Read the point cloud\n",
    "\n",
    "# Visualize the point cloud within open3d\n",
    "\n",
    "# Visualize the point cloud with normals\n",
    "mesh.normals = np.column_stack((np.array(vertices['nx']),np.array(vertices['ny']),np.array(vertices['nz'])))\n",
    "o3d.visualization.draw_geometries([mesh], point_show_normal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2bdbf26cac0>,\n",
       " <matplotlib.lines.Line2D at 0x2bdbf26cb20>,\n",
       " <matplotlib.lines.Line2D at 0x2bdbf26cb50>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(np.asarray(mesh.normals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<Figure size 640x480 with 1 Axes>,\n",
       " <matplotlib.image.AxesImage at 0x2bdbbc6b220>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# render image \n",
    "image_name = f'{image_names[0]}.jpg'\n",
    "\n",
    "cam1 = frames[image_name].get_croped_camera()\n",
    "cam4 = frames[f'{image_names[0]}.jpg'].get_croped_camera()\n",
    "\n",
    "rotmat = np.array([[1,0,0],[0,1,0],[0,0,1]])\n",
    "\n",
    "K_crop = cam4.K\n",
    "K_crop[0,0] = K_crop[0,0]\n",
    "K_crop[1,1] = K_crop[1,1]\n",
    "\n",
    "R = rotmat @ cam4.R\n",
    "X0 = cam4.X0 + np.array([[0,0,0]]).T\n",
    "cam = Camera(cam1.path,5,cam = {'camera': np.hstack((K_crop,R,X0))[:, :, np.newaxis]},image_size = [160,160])\n",
    "\n",
    "cam = frames[f'{image_names[0]}.jpg'].get_croped_camera()\n",
    "\n",
    "\n",
    "\n",
    "render = Render(gs,cam,tiles = [1,10],block_xy = [16,16], image_size = [160,160])\n",
    "image = render.render_image()\n",
    "plt.figure(),plt.imshow(image)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elliptical Gaussian (from EWA article) - Math explained\n",
    "\n",
    "\n",
    "we define an elliptical gaussian: \n",
    "\n",
    "Equation 1: $G_\\mathbf{V}(\\mathbf{x} - \\mathbf{p}) = \\frac{1}{2 \\pi |\\mathbf{V}|} \\frac{1}{2} e^{-\\frac{1}{2} (\\mathbf{x} - \\mathbf{p})^T \\mathbf{V}^{-1} (\\mathbf{x} - \\mathbf{p})}.$\n",
    "\n",
    "* $V$ is the covariance matrix\n",
    "* $\\mathbf{x}$ - a 3d coordinate (in gaussian axes)\n",
    "* $\\mathbf{p}$ - the mean of the gaussian \n",
    "### Affine projection of the gauusian\n",
    "We define an arbitrary affine mapping from object space $ \\mathbf{u} = \\Phi(\\mathbf{x}) $, where $ \\Phi(\\mathbf{x}) = \\mathbf{Mx + c} $, \n",
    "\n",
    "and we substitute $ \\mathbf{x} = \\Phi^{-1}(\\mathbf{u}) $. Since $ \\Phi^{-1}(\\mathbf{u}) = \\mathbf{M}^{-1}(\\mathbf{u} - \\mathbf{c}) $, we get:\n",
    "\n",
    "$$\n",
    "G_\\mathbf{V}(\\Phi^{-1}(\\mathbf{u}) - \\mathbf{p}) = \n",
    "\\frac{1}{|M^{-1}|} \\cdot \\frac{1}{(2 \\pi)^{3/2} |\\mathbf{V}|^{1/2}} e^{-\\frac{1}{2} (\\mathbf{M}^{-1}(\\mathbf{u} - \\mathbf{c}) - \\mathbf{p})^T \\mathbf{V}^{-1} (\\mathbf{M}^{-1}(\\mathbf{u} - \\mathbf{c}) - \\mathbf{p})} = \n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{1}{|M^{-1}|} \\cdot \\frac{1}{(2 \\pi)^{3/2} |\\mathbf{V}|^{1/2}} e^{-\\frac{1}{2} (\\mathbf{u} - \\mathbf{c} - \\mathbf{Mp})^T \\mathbf{M}^{-1} \\mathbf{V}^{-1} (\\mathbf{M}^{-1})^T (\\mathbf{u} - \\mathbf{c} - \\mathbf{Mp})} = \n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{1}{|M^{-1}|} \\cdot \\frac{1}{(2 \\pi)^{3/2} |\\mathbf{V}|^{1/2}} e^{-\\frac{1}{2} (\\mathbf{u} - \\Phi(\\mathbf{p}))^T (\\mathbf{MVM}^T)^{-1} (\\mathbf{u} - \\Phi(\\mathbf{p}))}.\n",
    "$$\n",
    "\n",
    "from this, to ease the writing we define equation 2: \n",
    "\n",
    "Equation 2: $G \\mathbf{V}(\\Phi^{-1}(u) - \\mathbf{p}) = \\frac{1}{|\\mathbf{M}^{-1}|} G_{ \\mathbf{M} \\mathbf{V} \\mathbf{M}^T} (u - \\Phi(\\mathbf{p})).$\n",
    "\n",
    "#### The covariance matrix\n",
    "$V$, the covariance matrix is a symetrix matrix that can be ragarded as a transformation. it scales and shears the data (thus defining the orientation and ratio between the gaussian principal axes). \n",
    "As mentioned above, the gaussian is transformed using an affine mapping $\\Phi(X)$. Usually we use this kind of mapping to transform a vector or a 3D point to a new FoR (change basis). Because the covariance matrix is a transformation, in order to change its FoR (basis), we will perform $\\mathbf{V_{1}} = MVM^{T}$. We first multiply $VM^{T}$  - transform (whatever xyz we multiply) from camera to body ($M^{T}$) and then multiply by $V$ which is in object coordinates - now we have coordinates in object basis after shear and scale. we then multiply by $M$ again to transform back to camera coordinates. \n",
    "\n",
    "\n",
    "### Projection\n",
    "\n",
    "\n",
    "![alt text](ray_ewa.png)\n",
    "#### Ray space\n",
    "\n",
    "We converted to camera space, now we want to convert to ray space. The coordinates in ray space are defined such that $x_0, x_1$ are the coordinates on the image plane and the devision by $u_2$ adds prespective. $u_3$ is then defined as the euclidean distance from the point to the origin (camera). \n",
    "\n",
    "\n",
    "$$ \\text{ray space to camera: }\n",
    "\\begin{pmatrix}\n",
    "x_0 \\\\\n",
    "x_1 \\\\\n",
    "x_2 \\\\\n",
    "\n",
    "\\end{pmatrix} = m(u) = \\begin{pmatrix}\n",
    "u_0 / u_2 \\\\\n",
    "u_1/u_2 \\\\\n",
    "||(u_0, u_1, u_2)||^{T} \\\\\n",
    "\\end{pmatrix}\n",
    "\n",
    "\\text{,camera to ray space: }\n",
    "\\begin{pmatrix}\n",
    "u_0 \\\\\n",
    "u_1 \\\\\n",
    "u_2 \\\\\n",
    "\n",
    "\\end{pmatrix} = m^{-1}(x) = \\begin{pmatrix}\n",
    "x_0/||(x_0,x_1,1)^T|| \\cdot x_2 \\\\\n",
    "x_1/||(x_0,x_1,1)^T|| \\cdot x_2 \\\\\n",
    "1/||(x_0,x_1,1)^T|| \\cdot x_2 \\\\\n",
    "\n",
    "\\end{pmatrix}\n",
    "\n",
    "\n",
    "$$\n",
    "  \n",
    "Ray space is defined with 3 coordinates $(x_0,x_1,x_2)$ where $x_0$ and $x_1$ represents the location of the pixel and $x_3$ is the euclidean distance from the camera origin to $(x_1,x_2). This transformation is not affine due to the devision by $u_2$, parallel lines are not preserved and the shape of the gaussian will be distorted. (in addition, the dimention is problematic).\n",
    "In order to solve this a local affine approximation $\\mathbf{m_{u_k}}$ of the projection transformation is defined. The approximation is the first to terms of the Tayor expansion of $\\mathbf{m}$ at point $\\mathbf{u}_{k}$:\n",
    "$$\\mathbf{m_{u_k}\\mathbf(u)} = \\mathbf x_k+\\mathbf J_{\\mathbf{u}_k}\\cdot ( \\mathbf u-\\mathbf u_k )$$\n",
    "where $\\mathbf x_k=\\mathbf m(\\mathbf u_k)$ is the mean of the gaussian in ray space (can be transformed using the mapping m, the projection matrix) and the Jacobian $ J_{u_k} = \\frac{\\partial m}{\\partial u}(u_k) $\n",
    "\n",
    "### The gaussian mapping\n",
    "#### Object to camera coordinates (as detailed in Affine projection of the gauusian)\n",
    "\n",
    "The reconstruction kernels are initially given in object space, which has coordinates $t =(t_0,t_1,t_2)^T$ . \n",
    "* Gaussian reconstruction kernels in object space: $r\"_k (t)=G_{V\"_k} (t − t_k)$, where $t_k$ are the voxel positions in object space\n",
    "* Object coordinates are transformed to camera coordinates using an affine mapping $\\mathbf u = \\phi(t)$, called viewing transformation. It is defined by a matrix $\\mathbf W$ and a translation vector $\\mathbf d$ as $\\phi(t) = Wt + d$. We transform the reconstruction kernels $G_{V\"k} (t − t_k)$ to camera space by substituting $t = \\phi ^{−1}(u)$ and using Equation 2 : \n",
    "\n",
    "$G \\mathbf{V\"_{k}}(\\Phi^{-1}(u) - t_k) = \\frac{1}{|\\mathbf{W}^{-1}|} G_{V'_k } (\\mathbf u - \\mathbf u_k) = r'_k(u\\mathbf).$\n",
    "\n",
    "where $u_k = \\phi(\\mathbf t_k)$ is the center of the Gaussian in camera coordinates and $r′_k(\\mathbf u)$ denotes the reconstruction kernel in camera space. According to equation 2, the covariance matrix in camera coordinates $V′_k$ is given by $V′_k = WV\"_kW^T$ (exactly as detailed in Affine projection of the gauusian).\n",
    "\n",
    "#### Camera to ray space\n",
    "Reminder: the local affine transformation - $$\\mathbf{m_{u_k}\\mathbf(u)} = \\mathbf x_k+\\mathbf J_{\\mathbf{u}_k}\\cdot ( \\mathbf u-\\mathbf u_k )$$\n",
    "$\\mathbf{m_{u_k}\\mathbf(u)}$ transforms from camera to ray, hence $x_k=m(u_k)$ where $x_k$ is the center of the gaussian in ray space. \n",
    "since $\\mathbf x = m(\\mathbf u)$ we get that $ u = \\mathbf m^{-1}(\\mathbf(x))$ hence: \n",
    "$$ u = \\mathbf m^{-1}(x) = \\mathbf(x - x_k)\\cdot \\mathbf J^{-1}_{\\mathbf u_k} + \\mathbf u_k $$\n",
    "$$ r_k(\\mathbf x) = \\frac{1}{|\\mathbf W^{-1}|}\\cdot G_{\\mathbf V'_k}(\\mathbf{(x - x_k)\\cdot J^{-1}_{\\mathbf u_k} + \\mathbf u_k - \\mathbf u_k}) = \\\\\n",
    "\\frac{1}{|\\mathbf W^{-1}||\\mathbf J^{-1}|}G_{\\mathbf V'_k}(J^{-1}_{\\mathbf u_k}\\mathbf{(x - x_k)})\\\\$$\n",
    "\n",
    "and the new covariance matrix is defined:  $Vk = JV'_{k}$ $J^T = JWV\"_kW^TJ^T$.\n",
    "where V\"_k is the original covariance matrix\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Perspective Projection and Jacobian Derivation\n",
    "\n",
    "In a pinhole camera model, the perspective projection of a 3D point \\((X, Y, Z)\\) into 2D image coordinates \\((x, y)\\) can be expressed as:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "x \\\\\n",
    "y \\\\\n",
    "1\n",
    "\\end{bmatrix} = \\frac{1}{Z} \\cdot\n",
    "\\begin{bmatrix}\n",
    "f_x \\cdot X + c_x \\cdot Z \\\\\n",
    "f_y \\cdot Y + c_y \\cdot Z \\\\\n",
    "Z\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "* $(x, y)$  : are the projected 2D coordinates on the image plane.\n",
    "* $(X, Y, Z)$  : are the coordinates in the 3D space. \n",
    "* $f_x , f_y$  : are the focal lengths in the x and y directions, respectively. \n",
    "* $c_x , c_y$  : are the coordinates of the principal point (optical center) in the image. \n",
    "\n",
    "### Derivation of the Jacobian\n",
    "\n",
    "To derive the Jacobian, we compute the partial derivatives of the projected 2D coordinates \\((x, y)\\) with respect to the 3D coordinates \\((X, Y, Z)\\).\n",
    "\n",
    "1. **From the perspective projection equations**:\n",
    "   - For \\(x\\):\n",
    "   $$\n",
    "   x = \\frac{f_x \\cdot X + c_x \\cdot Z}{Z}\n",
    "   $$\n",
    "   - For \\(y\\):\n",
    "   $$\n",
    "   y = \\frac{f_y \\cdot Y + c_y \\cdot Z}{Z}\n",
    "   $$\n",
    "\n",
    "2. **Calculating the derivatives**:\n",
    "   - The derivatives with respect to \\(Z\\) yield:\n",
    "     - For \\(x\\):\n",
    "     $$\n",
    "     \\frac{\\partial x}{\\partial X} = \\frac{f_x}{Z}, \\quad \\frac{\\partial x}{\\partial Y} = 0, \\quad \\frac{\\partial x}{\\partial Z} = -\\frac{f_x \\cdot X}{Z^2}\n",
    "     $$\n",
    "     - For \\(y\\):\n",
    "     $$\n",
    "     \\frac{\\partial y}{\\partial X} = 0, \\quad \\frac{\\partial y}{\\partial Y} = \\frac{f_y}{Z}, \\quad \\frac{\\partial y}{\\partial Z} = -\\frac{f_y \\cdot Y}{Z^2}\n",
    "     $$\n",
    "\n",
    "3. **Forming the Jacobian**:\n",
    "   Using the derivatives calculated above, the Jacobian matrix \\(J\\) becomes:\n",
    "   $$\n",
    "   J = \\begin{bmatrix}\n",
    "   \\frac{f_x}{Z} & 0 & -\\frac{f_x \\cdot X}{Z^2} \\\\\n",
    "   0 & \\frac{f_y}{Z} & -\\frac{f_y \\cdot Y}{Z^2}\n",
    "   \\end{bmatrix}\n",
    "   $$\n",
    "\n",
    "\n",
    "### 2D Projection \n",
    "We calculate the conics coeffitient for each gaussian : $$Ax^2+Bxy+Cy^2 = 0$$, where $A = \\frac{\\sigma_y^2}{|V|}$, $B = \\frac{\\sigma_xy}{|V|}$ and  $C = \\frac{\\sigma_x^2}{|V|}$\n",
    "we then multiply by the distace between the gaussiam and the pixel. this is the same as: \n",
    "$-\\frac{1}{2} (\\mathbf{x} - \\mathbf{p})^T \\mathbf{V}^{-1} (\\mathbf{x} - \\mathbf{p})$ - the exponent of the gaussian\n",
    "\n",
    "wIncorporating the scaled conic, which represents the 2D Gaussian as an ellipse in the Gaussian equation, we can express the effect of every Gaussian on the pixel's color as follows:\n",
    "\n",
    "$$\n",
    "G_{\\mathbf{V}}(\\mathbf{x}) = \\frac{1}{(2\\pi)^{3/2} |\\mathbf{V}|^{1/2}} e^{-\\frac{1}{2} ( Ax^2+Bxy+Cy^2)}\n",
    "$$\n",
    "\n",
    "This equation captures how each Gaussian contributes to the pixel's color based on its distance from the pixel and the shape defined by the covariance matrix.\n",
    "\n",
    "## tiles\n",
    "To render the image we devide it to tiles of $ 16 X 16 $, for each tile we sort the gaussians according to the distance from the camera. we then sample all gaussians effect per pixel in the tile (using the power equation to calculate the opacity). We sum the gaussians color values and multiply by the opacity (doing alpha blending, each time we update the opacity according to the already calculated gaussians $color = RGB * \\alpha *\\alpha_{blend})$ were for eacg gaussian we add we update $\\alpha_{blend} =  \\alpha_{blend}*(1-\\alpha) $ (when we reach 0, its opaque)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
