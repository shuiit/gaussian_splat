{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.insert(0, parent_dir)\n",
    "\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd().split('render')[0],'gaussian_data'))\n",
    "sys.path.insert(0, parent_dir)\n",
    "\n",
    "from gaussian_data.Camera import Camera\n",
    "from gaussian_data.Frame import Frame\n",
    "import gaussian_data.Plotters\n",
    "import gaussian_data.Utils as Utils\n",
    "\n",
    "from GaussianSplat import GaussianSplat\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from plyfile import PlyData\n",
    "import numpy as np\n",
    "import argparse\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "import Plotters\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "import scipy.io\n",
    "import pandas as pd\n",
    "from Render import Render\n",
    "\n",
    "%matplotlib qt\n",
    "\n",
    "# load hull\n",
    "path = 'G:/My Drive/Research/gs_data/mov19_2022_03_03/'\n",
    "real_coord = scipy.io.loadmat(f'{path}/3d_pts/real_coord.mat')['all_coords']\n",
    "points_3d = {body_wing : pd.DataFrame(Utils.load_hull(body_wing,path),columns = ['X','Y','Z','frame']) for body_wing in ['body','rwing','lwing']}\n",
    "# initilize objects\n",
    "frames = [1407]#list(range(500,700,13))\n",
    "\n",
    "image_names,points_in_idx = Utils.define_frames(frames,points_3d)\n",
    "cameras = {f'cam{cam + 1}':Camera(path,cam) for cam in range(4)}\n",
    "frames = {f'{im_name}.jpg':Frame(path,im_name,points_in_idx[im_name.split('CAM')[0]],real_coord,idx) for idx,im_name in enumerate(image_names)}\n",
    "# map 3d voxels to 2d pixels\n",
    "[frames[im_name].map_3d_2d(croped_image = True) for im_name in frames.keys()]\n",
    "voxel_dict,colors_dict = Utils.get_dict_for_points3d(frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load gaussian splatting output\n",
    "input_file = \"G:/My Drive/Research/gs_data/mov19_2022_03_03/output/frame140845_scaling_lr0.005_percent_dense0.0001_densify_grad_threshold0.0002_position_lr_init12/point_cloud/iteration_60000/point_cloud.ply\"\n",
    "# input_file = \"D:\\Documents/2dgs_output/point_cloud3.ply\"\n",
    "input_file = \"I:/My Drive/Research/gs_data/mov19_2022_03_03/time/time2_norm01_dist1000000_iter200_start100_moreFr/1419/point_cloud/iteration_200/point_cloud.ply\"\n",
    "input_file = \"I:/My Drive/Research/gs_data/mov19_2022_03_03/time/densification_interval_500_opacity_reset_interval_100_all_def_lambda_dist_5_densify_until_iter1000_lambda_normal0.05_lr0.001_ori_100/1407/point_cloud/iteration_1300/point_cloud.ply\"\n",
    "input_file = \"G:/My Drive/Research/gs_data/mov19_2022_03_03/sweep/densification_interval_500_opacity_reset_interval_100_all_def_lambda_dist_5_densify_until_iter1000_lambda_normal0.05_lr0.001_ori_100/1408/point_cloud/iteration_1500/point_cloud.ply\"\n",
    "input_file = \"D:/Documents/output/30e0c1cc-8/point_cloud/iteration_30000/point_cloud.ply\"\n",
    "input_file = \"D:/Documents/output/d867e105-f/point_cloud/iteration_30000/point_cloud.ply\"\n",
    "\n",
    "gs = GaussianSplat(input_file)  \n",
    "gs.save_gs('_2dsplat')\n",
    "# reproject and filter background\n",
    "gs_filtered = gs.filter(gs.projection_filter(frames,gs.xyz,croped_image = True),path = gs.path)\n",
    "gs_filtered.save_gs('_filtered')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sh_utils\n",
    "\n",
    "vertices = PlyData.read(input_file)[\"vertex\"]\n",
    "vertices = gs.xyz\n",
    "\n",
    "# sh = np.column_stack([vertices[key] for key in vertices.data.dtype.names if 'rest' in key or 'dc' in key])\n",
    "# rgb = sh_utils.rgb_from_sh(0,sh,xyz = None,camera_position = None)\n",
    "# xyz = np.column_stack((vertices[\"x\"], vertices[\"y\"], vertices[\"z\"]))\n",
    "\n",
    "\n",
    "sh = gs.sh\n",
    "rgb = gs.color\n",
    "xyz = gs.xyz\n",
    "opacity = gs.opacity\n",
    "\n",
    "[frames[im_name].map_3d_2d(croped_image = True, use_zbuff = True) for im_name in frames.keys()]\n",
    "fig = go.Figure()\n",
    "color_pts = ['red','green','blue','black']\n",
    "fig = go.Figure()\n",
    "im_name = list(frames.keys())[0]\n",
    "for cam in range(4):\n",
    "    image = f'{im_name.split(\"CAM\")[0]}CAM{cam+1}.jpg'\n",
    "    Plotters.scatter3d(fig,frames[image].voxels_with_idx,color_pts[cam],3)\n",
    "opacity = 1 / (1 + np.exp(-opacity))   \n",
    "\n",
    "vertices = vertices[(rgb[:,0] < 0.9) & (rgb[:,0] > 0) & (opacity > 0.1) & (rgb[:,2] < 0.9) & (rgb[:,2] > 0) & (rgb[:,1] < 0.9) & (rgb[:,1] > 0)]\n",
    "rgb2 = rgb[(rgb[:,0] < 0.9) & (rgb[:,0] > 0) & (opacity > 0.1) & (rgb[:,2] < 0.9) & (rgb[:,2] > 0) & (rgb[:,1] < 0.9) & (rgb[:,1] > 0)]\n",
    "opacity = opacity[(rgb[:,0] < 0.9) & (rgb[:,0] > 0) & (opacity > 0.1) & (rgb[:,2] < 0.9) & (rgb[:,2] > 0) & (rgb[:,1] < 0.9) & (rgb[:,1] > 0)]\n",
    "# Create the 3D scatter plot with hover template for color value\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=xyz[:,0],\n",
    "    y=xyz[:,1],\n",
    "    z=xyz[:,2],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=3,\n",
    "        color=opacity,  # Color for each point\n",
    "        colorscale='Gray',  # Choose a colorscale\n",
    "        opacity=0.5,  # Use the opacity per point\n",
    "        colorbar=dict(title=\"Colorbar\")  # Optional colorbar\n",
    "    ),\n",
    "    hovertemplate='Color: %{marker.color:.4f}<extra></extra>',  # Show color as float\n",
    "))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Figure size 640x480 with 1 Axes>,\n",
       " <matplotlib.image.AxesImage at 0x1c19e8a32b0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cam = frames[f'{image_names[2]}.jpg'].get_croped_camera()\n",
    "render = Render(gs,cam,tiles = [1,10],block_xy = [16,16], image_size = [160,160],gaus3d = False,filtersze = 0.707)\n",
    "\n",
    "image = render.render_image()\n",
    "plt.figure(),plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiled_axes = np.tile(gs.radius,(2,1)).T\n",
    "radii = np.hstack([tiled_axes,gs.radius[:,np.newaxis]*0 + 0.1])\n",
    "# Example ellipsoid parameters\n",
    "centers = gs.xyz[radii[:,0]<10]  # Centers of ellipsoids\n",
    "\n",
    "rotations = gs.rotation[radii[:,0]<10]  # Rotation matrices (identity here)\n",
    "sum(radii[:,0]<7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def plot_ellipse_in_3d(center, radii, rotation_matrix, ax, num_points=100):\n",
    "    \"\"\"\n",
    "    Plots a single 2D ellipse in 3D space.\n",
    "    \n",
    "    Args:\n",
    "        center (array-like): The 3D coordinates of the ellipse center (x, y, z).\n",
    "        radii (array-like): The radii of the ellipse (r_x, r_y).\n",
    "        rotation_matrix (ndarray): A 3x3 rotation matrix for the ellipse orientation.\n",
    "        ax (Axes3D): A Matplotlib 3D axis object.\n",
    "        num_points (int): Number of points to represent the ellipse.\n",
    "    \"\"\"\n",
    "    # Create a 2D ellipse in its local coordinate system\n",
    "    theta = np.linspace(0, 2 * np.pi, num_points)\n",
    "    ellipse_2d = np.array([radii[0] * np.cos(theta), radii[1] * np.sin(theta), np.zeros_like(theta)])\n",
    "    \n",
    "    # Rotate the ellipse to its orientation in 3D space\n",
    "    ellipse_3d = rotation_matrix @ ellipse_2d\n",
    "    \n",
    "    # Translate the ellipse to its center in 3D space\n",
    "    ellipse_3d += np.array(center).reshape(3, 1)\n",
    "    \n",
    "    # Plot the ellipse\n",
    "    ax.plot(ellipse_3d[0, :], ellipse_3d[1, :], ellipse_3d[2, :])\n",
    "\n",
    "# Define your data: centers, radii, and rotation matrices\n",
    "# Example ellipsoid parameters\n",
    "tiled_axes = np.tile(gs.radius,(2,1)).T\n",
    "radii = gs.axes\n",
    "radius = gs.radius\n",
    "# Example ellipsoid parameters\n",
    "centers = gs.xyz[radius<10]  # Centers of ellipsoids\n",
    "rotation_matrices = gs.rotation[radius<10]  # Rotation matrices (identity here)\n",
    "radii = radii[radius<10]\n",
    "\n",
    "# Create a 3D plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Plot each ellipse\n",
    "for center, radii, rotation_matrix in zip(centers, radii, rotation_matrices):\n",
    "    plot_ellipse_in_3d(center, radii, rotation_matrix, ax)\n",
    "\n",
    "# Set labels and aspect\n",
    "ax.set_xlabel(\"X\")\n",
    "ax.set_ylabel(\"Y\")\n",
    "ax.set_zlabel(\"Z\")\n",
    "ax.set_box_aspect([1, 1, 1])  # Equal aspect ratio\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def plot_colored_ellipse_in_3d(center, radii, rotation_matrix, ax, color='blue', alpha=0.5, num_points=100):\n",
    "    \"\"\"\n",
    "    Plots a single 2D ellipse in 3D space with color and opacity.\n",
    "    \n",
    "    Args:\n",
    "        center (array-like): The 3D coordinates of the ellipse center (x, y, z).\n",
    "        radii (array-like): The radii of the ellipse (r_x, r_y).\n",
    "        rotation_matrix (ndarray): A 3x3 rotation matrix for the ellipse orientation.\n",
    "        ax (Axes3D): A Matplotlib 3D axis object.\n",
    "        color (str): Color of the ellipse.\n",
    "        alpha (float): Opacity of the ellipse (0 is fully transparent, 1 is fully opaque).\n",
    "        num_points (int): Number of points to represent the ellipse.\n",
    "    \"\"\"\n",
    "    # Create a 2D ellipse in its local coordinate system\n",
    "    theta = np.linspace(0, 2 * np.pi, num_points)\n",
    "    ellipse_2d = np.array([radii[0] * np.cos(theta), radii[1] * np.sin(theta), np.zeros_like(theta)])\n",
    "    \n",
    "    # Rotate the ellipse to its orientation in 3D space\n",
    "    ellipse_3d = rotation_matrix @ ellipse_2d\n",
    "    \n",
    "    # Translate the ellipse to its center in 3D space\n",
    "    ellipse_3d += np.array(center).reshape(3, 1)\n",
    "    \n",
    "    # Generate a mesh for the ellipse\n",
    "    X, Y, Z = ellipse_3d[0], ellipse_3d[1], ellipse_3d[2]\n",
    "    \n",
    "    # Triangulate for surface plotting\n",
    "    ax.plot_trisurf(X, Y, Z, color=color, alpha=alpha)\n",
    "\n",
    "# Define your data: centers, radii, and rotation matrices\n",
    "idx = (gs.opacity < 1) & (gs.opacity > 0) & (gs.color[:,0] > 0) & (gs.color[:,1] > 0) & (gs.color[:,2] > 0)\n",
    "centers = gs.xyz[idx]  # Centers of ellipsoids\n",
    "rotation_matrices = gs.rotation[idx]  # Rotation matrices\n",
    "radii = gs.axes[idx]  # Radii\n",
    "\n",
    "# Create a 3D plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Colors for each ellipse (use a colormap or specify colors directly)\n",
    "colors = gs.color[idx]\n",
    "alpha = gs.opacity[idx]\n",
    "\n",
    "# Plot each ellipse\n",
    "for center, radii, rotation_matrix, color, opa in zip(centers, radii, rotation_matrices, colors,alpha):\n",
    "    plot_colored_ellipse_in_3d(center, radii, rotation_matrix, ax, color=color, alpha=opa)\n",
    "\n",
    "# Set labels and aspect\n",
    "ax.set_xlabel(\"X\")\n",
    "ax.set_ylabel(\"Y\")\n",
    "ax.set_zlabel(\"Z\")\n",
    "ax.set_box_aspect([1, 1, 1])  # Equal aspect ratio\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0027495 , -0.0027495 , -0.00275007])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def generate_ellipsoid(center, radii, rotation_matrix, u_samples=50, v_samples=50):\n",
    "    u = np.linspace(0, 2 * np.pi, u_samples)\n",
    "    v = np.linspace(0, np.pi, v_samples)\n",
    "    x = radii[0] * np.outer(np.cos(u), np.sin(v))\n",
    "    y = radii[1] * np.outer(np.sin(u), np.sin(v))\n",
    "    z = radii[2] * np.outer(np.ones_like(u), np.cos(v))\n",
    "    \n",
    "    # Apply rotation and translation\n",
    "    points = np.dot(rotation_matrix, np.array([x.ravel(), y.ravel(), z.ravel()]))\n",
    "    x, y, z = points[0].reshape(x.shape), points[1].reshape(y.shape), points[2].reshape(z.shape)\n",
    "    \n",
    "    return x + center[0], y + center[1], z + center[2]\n",
    "# Example ellipsoid parameters\n",
    "tiled_axes = np.tile(gs.radius,(2,1)).T\n",
    "radii = np.hstack([tiled_axes,gs.radius[:,np.newaxis]*0 + 0.1])\n",
    "# Example ellipsoid parameters\n",
    "centers = gs.xyz[radii[:,0]<7]  # Centers of ellipsoids\n",
    "rotations = gs.rotation[radii[:,0]<7]  # Rotation matrices (identity here)\n",
    "radii = radii[radii[:,0]<7]\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for center, radius, rotation in zip(centers, radii, rotations):\n",
    "    # Generate ellipsoid surface\n",
    "    x, y, z = generate_ellipsoid(center, radius, rotation)\n",
    "    fig.add_trace(go.Surface(x=x, y=y, z=z, opacity=0.5, colorscale='Viridis'))\n",
    "    \n",
    "    # Add principal axes\n",
    "    for i in range(3):\n",
    "        axis_start = center - radius[i] * rotation[:, i]\n",
    "        axis_end = center + radius[i] * rotation[:, i]\n",
    "        fig.add_trace(go.Scatter3d(\n",
    "            x=[axis_start[0], axis_end[0]],\n",
    "            y=[axis_start[1], axis_end[1]],\n",
    "            z=[axis_start[2], axis_end[2]],\n",
    "            mode='lines',\n",
    "            line=dict(color='red', width=4)\n",
    "        ))\n",
    "\n",
    "# Set layout\n",
    "fig.update_layout(scene=dict(\n",
    "    xaxis_title='X',\n",
    "    yaxis_title='Y',\n",
    "    zaxis_title='Z'\n",
    "))\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.31455401e-04, 2.04177949e-05, 1.60000000e-10],\n",
       "       [1.43049244e-04, 2.86818056e-05, 1.60000000e-10],\n",
       "       [5.52020167e-05, 3.68848277e-05, 1.60000000e-10],\n",
       "       ...,\n",
       "       [5.93517494e-05, 1.06731518e-04, 1.60000000e-10],\n",
       "       [4.35989386e-05, 7.56119080e-05, 1.60000000e-10],\n",
       "       [8.90756940e-05, 2.15409881e-05, 1.60000000e-10]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure(),plt.imshow(render.distortion)\n",
    "plt.figure(),plt.imshow(render.depth)\n",
    "plt.figure(),plt.imshow(render.median_depth)\n",
    "plt.figure(),plt.imshow(render.alpha_map,'gray')\n",
    "\n",
    "shape = render.normal_map.shape\n",
    "\n",
    "image_reshaped = render.normal_map.reshape(-1, 3)  # Flatten spatial dimensions\n",
    "transformed = (cam.world_to_cam[:,:3] @ image_reshaped.T).T \n",
    "\n",
    "image_transformed = transformed.reshape(shape[0], shape[1], 3)\n",
    "plt.figure()\n",
    "plt.imshow(image_transformed[:,:,:]*0.5 + 0.5)\n",
    "\n",
    "gs.scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roni\\AppData\\Local\\Temp\\ipykernel_25240\\2664146519.py:1: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\Roni\\AppData\\Local\\Temp\\ipykernel_25240\\2664146519.py:2: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x203fe9013f0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure(),plt.imshow(render.depth/render.alpha_map)\n",
    "depth_expected = render.depth/render.alpha_map\n",
    "depth_ratio = 1\n",
    "surf_depth = depth_expected*(1-depth_ratio) + (depth_ratio) * render.median_depth\n",
    "surf_depth[np.isnan(surf_depth)] = 0\n",
    "\n",
    "depth = surf_depth / surf_depth.max()\n",
    "plt.imshow(depth, cmap='turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(depth, cmap='turbo', vmin=depth.min(), vmax=depth.max())\n",
    "plt.colorbar()\n",
    "plt.title('Depth Map with Turbo Colormap')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'm' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 22\u001b[0m\n\u001b[0;32m     17\u001b[0m cam \u001b[38;5;241m=\u001b[39m frames[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_names[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mget_croped_camera()\n\u001b[0;32m     21\u001b[0m render \u001b[38;5;241m=\u001b[39m Render(gs,cam,tiles \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m10\u001b[39m],block_xy \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m16\u001b[39m,\u001b[38;5;241m16\u001b[39m], image_size \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m160\u001b[39m,\u001b[38;5;241m160\u001b[39m])\n\u001b[1;32m---> 22\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mrender\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(),plt\u001b[38;5;241m.\u001b[39mimshow(image)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# plt.figure(),plt.imshow(render.depth)\u001b[39;00m\n",
      "File \u001b[1;32md:\\Documents\\gaussian_splat\\render\\Render.py:127\u001b[0m, in \u001b[0;36mRender.render_image\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrender_image\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;124;03m    Renders the final image by iterating over each tile and calculating pixel values.\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \n\u001b[0;32m    124\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;124;03m        np.array: The rendered image as a 3D numpy array (height, width, color channels).\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 127\u001b[0m     [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalc_pixels_value_in_tile(tile) \u001b[38;5;28;01mfor\u001b[39;00m tile \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtiles]\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrendered_image\n",
      "File \u001b[1;32md:\\Documents\\gaussian_splat\\render\\Render.py:127\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrender_image\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;124;03m    Renders the final image by iterating over each tile and calculating pixel values.\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \n\u001b[0;32m    124\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;124;03m        np.array: The rendered image as a 3D numpy array (height, width, color channels).\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 127\u001b[0m     [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalc_pixels_value_in_tile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtile\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m tile \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtiles]\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrendered_image\n",
      "File \u001b[1;32md:\\Documents\\gaussian_splat\\render\\Render.py:142\u001b[0m, in \u001b[0;36mRender.calc_pixels_value_in_tile\u001b[1;34m(self, tile)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtiles[tile][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprojection\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m pixel \u001b[38;5;129;01min\u001b[39;00m pixels_in_tile:\n\u001b[1;32m--> 142\u001b[0m         pixel_value,temp_alpha,depth,distortion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalc_pixel_value\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtiles\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtile\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpixel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    143\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrendered_image[pixel[\u001b[38;5;241m1\u001b[39m],pixel[\u001b[38;5;241m0\u001b[39m]] \u001b[38;5;241m=\u001b[39m pixel_value \u001b[38;5;241m+\u001b[39m temp_alpha\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m    144\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdepth[pixel[\u001b[38;5;241m1\u001b[39m],pixel[\u001b[38;5;241m0\u001b[39m]] \u001b[38;5;241m=\u001b[39m depth \n",
      "File \u001b[1;32md:\\Documents\\gaussian_splat\\render\\Render.py:101\u001b[0m, in \u001b[0;36mRender.calc_pixel_value\u001b[1;34m(self, tile_params, pixel)\u001b[0m\n\u001b[0;32m     99\u001b[0m image,T \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msum_all_gs_in_tile(alpha[idx_to_keep],tile_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolor\u001b[39m\u001b[38;5;124m'\u001b[39m][idx_to_keep])\n\u001b[0;32m    100\u001b[0m depth,T \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msum_all_gs_in_tile(alpha[idx_to_keep],tile_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcam_coord\u001b[39m\u001b[38;5;124m'\u001b[39m][idx_to_keep,\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m--> 101\u001b[0m distortion,T \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msum_all_depth_in_tile(alpha[idx_to_keep],\u001b[43mm\u001b[49m[idx_to_keep])\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(distortion) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    103\u001b[0m     wakk \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'm' referenced before assignment"
     ]
    }
   ],
   "source": [
    "# render image \n",
    "image_name = f'{image_names[0]}.jpg'\n",
    "\n",
    "cam1 = frames[image_name].get_croped_camera()\n",
    "cam4 = frames[f'{image_names[0]}.jpg'].get_croped_camera()\n",
    "\n",
    "rotmat = np.array([[1,0,0],[0,1,0],[0,0,1]])\n",
    "\n",
    "K_crop = cam4.K\n",
    "K_crop[0,0] = K_crop[0,0]\n",
    "K_crop[1,1] = K_crop[1,1]\n",
    "\n",
    "R = rotmat @ cam4.R\n",
    "X0 = cam4.X0 + np.array([[0,0,0]]).T\n",
    "cam = Camera(cam1.path,5,cam = {'camera': np.hstack((K_crop,R,X0))[:, :, np.newaxis]},image_size = [160,160])\n",
    "\n",
    "cam = frames[f'{image_names[0]}.jpg'].get_croped_camera()\n",
    "\n",
    "\n",
    "\n",
    "render = Render(gs,cam,tiles = [1,10],block_xy = [16,16], image_size = [160,160])\n",
    "image = render.render_image()\n",
    "plt.figure(),plt.imshow(image)\n",
    "# plt.figure(),plt.imshow(render.depth)\n",
    "np.unique(render.depth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.06498141e-05, 7.69689944e-05, 1.60000000e-06],\n",
       "       [7.98608723e-05, 8.76289931e-05, 1.60000000e-06],\n",
       "       [8.31628697e-05, 9.40807091e-05, 1.60000000e-06],\n",
       "       ...,\n",
       "       [9.92269857e-05, 8.62566106e-05, 1.60000000e-06],\n",
       "       [8.34508671e-05, 5.89549979e-05, 1.60000000e-06],\n",
       "       [7.89204542e-05, 8.14726523e-05, 1.60000000e-06]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'T' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m cam \u001b[38;5;241m=\u001b[39m frames[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_names[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mget_croped_camera()\n\u001b[1;32m----> 2\u001b[0m render \u001b[38;5;241m=\u001b[39m Render(gs,cam,tiles \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m10\u001b[39m],block_xy \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m16\u001b[39m,\u001b[38;5;241m16\u001b[39m], image_size \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m160\u001b[39m,\u001b[38;5;241m160\u001b[39m],T \u001b[38;5;241m=\u001b[39m \u001b[43mT\u001b[49m,center \u001b[38;5;241m=\u001b[39m center,gaus3d \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m image \u001b[38;5;241m=\u001b[39m render\u001b[38;5;241m.\u001b[39mrender_image()\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(),plt\u001b[38;5;241m.\u001b[39mimshow(image)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'T' is not defined"
     ]
    }
   ],
   "source": [
    "cam = frames[f'{image_names[0]}.jpg'].get_croped_camera()\n",
    "render = Render(gs,cam,tiles = [1,10],block_xy = [16,16], image_size = [160,160],T = T,center = center,gaus3d = True)\n",
    "\n",
    "image = render.render_image()\n",
    "plt.figure(),plt.imshow(image)\n",
    "# plt.figure(),plt.imshow(render.depth)\n",
    "np.unique(render.depth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# projection\n",
    "xyz = np.column_stack((vertices[\"x\"], vertices[\"y\"], vertices[\"z\"]))\n",
    "\n",
    "im_name= 'P1408CAM1.jpg'\n",
    "fig,axs = plt.subplots(2,2)\n",
    "for cam in range(4):\n",
    "    cam_obj  = frames[f'{image_names[cam]}.jpg'].get_croped_camera()\n",
    "\n",
    "    image = f'{im_name.split(\"CAM\")[0]}CAM{cam+1}.jpg'\n",
    "    homo_voxels_with_idx = frames[image].add_homo_coords(xyz)\n",
    "    proj = cam_obj.project_with_proj_mat(xyz)\n",
    "    axs[cam // 2,cam % 2].imshow(frames[image].croped_image)\n",
    "    axs[cam // 2,cam % 2].scatter(proj[:,0],proj[:,1],s = 3,c = rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elliptical Gaussian (from EWA article) - Math explained\n",
    "\n",
    "\n",
    "we define an elliptical gaussian: \n",
    "\n",
    "Equation 1: $G_\\mathbf{V}(\\mathbf{x} - \\mathbf{p}) = \\frac{1}{2 \\pi |\\mathbf{V}|} \\frac{1}{2} e^{-\\frac{1}{2} (\\mathbf{x} - \\mathbf{p})^T \\mathbf{V}^{-1} (\\mathbf{x} - \\mathbf{p})}.$\n",
    "\n",
    "* $V$ is the covariance matrix\n",
    "* $\\mathbf{x}$ - a 3d coordinate (in gaussian axes)\n",
    "* $\\mathbf{p}$ - the mean of the gaussian \n",
    "### Affine projection of the gauusian\n",
    "We define an arbitrary affine mapping from object space $ \\mathbf{u} = \\Phi(\\mathbf{x}) $, where $ \\Phi(\\mathbf{x}) = \\mathbf{Mx + c} $, \n",
    "\n",
    "and we substitute $ \\mathbf{x} = \\Phi^{-1}(\\mathbf{u}) $. Since $ \\Phi^{-1}(\\mathbf{u}) = \\mathbf{M}^{-1}(\\mathbf{u} - \\mathbf{c}) $, we get:\n",
    "\n",
    "$$\n",
    "G_\\mathbf{V}(\\Phi^{-1}(\\mathbf{u}) - \\mathbf{p}) = \n",
    "\\frac{1}{|M^{-1}|} \\cdot \\frac{1}{(2 \\pi)^{3/2} |\\mathbf{V}|^{1/2}} e^{-\\frac{1}{2} (\\mathbf{M}^{-1}(\\mathbf{u} - \\mathbf{c}) - \\mathbf{p})^T \\mathbf{V}^{-1} (\\mathbf{M}^{-1}(\\mathbf{u} - \\mathbf{c}) - \\mathbf{p})} = \n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{1}{|M^{-1}|} \\cdot \\frac{1}{(2 \\pi)^{3/2} |\\mathbf{V}|^{1/2}} e^{-\\frac{1}{2} (\\mathbf{u} - \\mathbf{c} - \\mathbf{Mp})^T \\mathbf{M}^{-1} \\mathbf{V}^{-1} (\\mathbf{M}^{-1})^T (\\mathbf{u} - \\mathbf{c} - \\mathbf{Mp})} = \n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{1}{|M^{-1}|} \\cdot \\frac{1}{(2 \\pi)^{3/2} |\\mathbf{V}|^{1/2}} e^{-\\frac{1}{2} (\\mathbf{u} - \\Phi(\\mathbf{p}))^T (\\mathbf{MVM}^T)^{-1} (\\mathbf{u} - \\Phi(\\mathbf{p}))}.\n",
    "$$\n",
    "\n",
    "from this, to ease the writing we define equation 2: \n",
    "\n",
    "Equation 2: $G \\mathbf{V}(\\Phi^{-1}(u) - \\mathbf{p}) = \\frac{1}{|\\mathbf{M}^{-1}|} G_{ \\mathbf{M} \\mathbf{V} \\mathbf{M}^T} (u - \\Phi(\\mathbf{p})).$\n",
    "\n",
    "#### The covariance matrix\n",
    "$V$, the covariance matrix is a symetrix matrix that can be ragarded as a transformation. it scales and shears the data (thus defining the orientation and ratio between the gaussian principal axes). \n",
    "As mentioned above, the gaussian is transformed using an affine mapping $\\Phi(X)$. Usually we use this kind of mapping to transform a vector or a 3D point to a new FoR (change basis). Because the covariance matrix is a transformation, in order to change its FoR (basis), we will perform $\\mathbf{V_{1}} = MVM^{T}$. We first multiply $VM^{T}$  - transform (whatever xyz we multiply) from camera to body ($M^{T}$) and then multiply by $V$ which is in object coordinates - now we have coordinates in object basis after shear and scale. we then multiply by $M$ again to transform back to camera coordinates. \n",
    "\n",
    "\n",
    "### Projection\n",
    "\n",
    "\n",
    "![alt text](ray_ewa.png)\n",
    "#### Ray space\n",
    "\n",
    "We converted to camera space, now we want to convert to ray space. The coordinates in ray space are defined such that $x_0, x_1$ are the coordinates on the image plane and the devision by $u_2$ adds prespective. $u_3$ is then defined as the euclidean distance from the point to the origin (camera). \n",
    "\n",
    "\n",
    "$$ \\text{ray space to camera: }\n",
    "\\begin{pmatrix}\n",
    "x_0 \\\\\n",
    "x_1 \\\\\n",
    "x_2 \\\\\n",
    "\n",
    "\\end{pmatrix} = m(u) = \\begin{pmatrix}\n",
    "u_0 / u_2 \\\\\n",
    "u_1/u_2 \\\\\n",
    "||(u_0, u_1, u_2)||^{T} \\\\\n",
    "\\end{pmatrix}\n",
    "\n",
    "\\text{,camera to ray space: }\n",
    "\\begin{pmatrix}\n",
    "u_0 \\\\\n",
    "u_1 \\\\\n",
    "u_2 \\\\\n",
    "\n",
    "\\end{pmatrix} = m^{-1}(x) = \\begin{pmatrix}\n",
    "x_0/||(x_0,x_1,1)^T|| \\cdot x_2 \\\\\n",
    "x_1/||(x_0,x_1,1)^T|| \\cdot x_2 \\\\\n",
    "1/||(x_0,x_1,1)^T|| \\cdot x_2 \\\\\n",
    "\n",
    "\\end{pmatrix}\n",
    "\n",
    "\n",
    "$$\n",
    "  \n",
    "Ray space is defined with 3 coordinates $(x_0,x_1,x_2)$ where $x_0$ and $x_1$ represents the location of the pixel and $x_3$ is the euclidean distance from the camera origin to $(x_1,x_2). This transformation is not affine due to the devision by $u_2$, parallel lines are not preserved and the shape of the gaussian will be distorted. (in addition, the dimention is problematic).\n",
    "In order to solve this a local affine approximation $\\mathbf{m_{u_k}}$ of the projection transformation is defined. The approximation is the first to terms of the Tayor expansion of $\\mathbf{m}$ at point $\\mathbf{u}_{k}$:\n",
    "$$\\mathbf{m_{u_k}\\mathbf(u)} = \\mathbf x_k+\\mathbf J_{\\mathbf{u}_k}\\cdot ( \\mathbf u-\\mathbf u_k )$$\n",
    "where $\\mathbf x_k=\\mathbf m(\\mathbf u_k)$ is the mean of the gaussian in ray space (can be transformed using the mapping m, the projection matrix) and the Jacobian $ J_{u_k} = \\frac{\\partial m}{\\partial u}(u_k) $\n",
    "\n",
    "### The gaussian mapping\n",
    "#### Object to camera coordinates (as detailed in Affine projection of the gauusian)\n",
    "\n",
    "The reconstruction kernels are initially given in object space, which has coordinates $t =(t_0,t_1,t_2)^T$ . \n",
    "* Gaussian reconstruction kernels in object space: $r\"_k (t)=G_{V\"_k} (t − t_k)$, where $t_k$ are the voxel positions in object space\n",
    "* Object coordinates are transformed to camera coordinates using an affine mapping $\\mathbf u = \\phi(t)$, called viewing transformation. It is defined by a matrix $\\mathbf W$ and a translation vector $\\mathbf d$ as $\\phi(t) = Wt + d$. We transform the reconstruction kernels $G_{V\"k} (t − t_k)$ to camera space by substituting $t = \\phi ^{−1}(u)$ and using Equation 2 : \n",
    "\n",
    "$G \\mathbf{V\"_{k}}(\\Phi^{-1}(u) - t_k) = \\frac{1}{|\\mathbf{W}^{-1}|} G_{V'_k } (\\mathbf u - \\mathbf u_k) = r'_k(u\\mathbf).$\n",
    "\n",
    "where $u_k = \\phi(\\mathbf t_k)$ is the center of the Gaussian in camera coordinates and $r′_k(\\mathbf u)$ denotes the reconstruction kernel in camera space. According to equation 2, the covariance matrix in camera coordinates $V′_k$ is given by $V′_k = WV\"_kW^T$ (exactly as detailed in Affine projection of the gauusian).\n",
    "\n",
    "#### Camera to ray space\n",
    "Reminder: the local affine transformation - $$\\mathbf{m_{u_k}\\mathbf(u)} = \\mathbf x_k+\\mathbf J_{\\mathbf{u}_k}\\cdot ( \\mathbf u-\\mathbf u_k )$$\n",
    "$\\mathbf{m_{u_k}\\mathbf(u)}$ transforms from camera to ray, hence $x_k=m(u_k)$ where $x_k$ is the center of the gaussian in ray space. \n",
    "since $\\mathbf x = m(\\mathbf u)$ we get that $ u = \\mathbf m^{-1}(\\mathbf(x))$ hence: \n",
    "$$ u = \\mathbf m^{-1}(x) = \\mathbf(x - x_k)\\cdot \\mathbf J^{-1}_{\\mathbf u_k} + \\mathbf u_k $$\n",
    "$$ r_k(\\mathbf x) = \\frac{1}{|\\mathbf W^{-1}|}\\cdot G_{\\mathbf V'_k}(\\mathbf{(x - x_k)\\cdot J^{-1}_{\\mathbf u_k} + \\mathbf u_k - \\mathbf u_k}) = \\\\\n",
    "\\frac{1}{|\\mathbf W^{-1}||\\mathbf J^{-1}|}G_{\\mathbf V'_k}(J^{-1}_{\\mathbf u_k}\\mathbf{(x - x_k)})\\\\$$\n",
    "\n",
    "and the new covariance matrix is defined:  $Vk = JV'_{k}$ $J^T = JWV\"_kW^TJ^T$.\n",
    "where V\"_k is the original covariance matrix\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Perspective Projection and Jacobian Derivation\n",
    "\n",
    "In a pinhole camera model, the perspective projection of a 3D point \\((X, Y, Z)\\) into 2D image coordinates \\((x, y)\\) can be expressed as:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "x \\\\\n",
    "y \\\\\n",
    "1\n",
    "\\end{bmatrix} = \\frac{1}{Z} \\cdot\n",
    "\\begin{bmatrix}\n",
    "f_x \\cdot X + c_x \\cdot Z \\\\\n",
    "f_y \\cdot Y + c_y \\cdot Z \\\\\n",
    "Z\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "* $(x, y)$  : are the projected 2D coordinates on the image plane.\n",
    "* $(X, Y, Z)$  : are the coordinates in the 3D space. \n",
    "* $f_x , f_y$  : are the focal lengths in the x and y directions, respectively. \n",
    "* $c_x , c_y$  : are the coordinates of the principal point (optical center) in the image. \n",
    "\n",
    "### Derivation of the Jacobian\n",
    "\n",
    "To derive the Jacobian, we compute the partial derivatives of the projected 2D coordinates \\((x, y)\\) with respect to the 3D coordinates \\((X, Y, Z)\\).\n",
    "\n",
    "1. **From the perspective projection equations**:\n",
    "   - For \\(x\\):\n",
    "   $$\n",
    "   x = \\frac{f_x \\cdot X + c_x \\cdot Z}{Z}\n",
    "   $$\n",
    "   - For \\(y\\):\n",
    "   $$\n",
    "   y = \\frac{f_y \\cdot Y + c_y \\cdot Z}{Z}\n",
    "   $$\n",
    "\n",
    "2. **Calculating the derivatives**:\n",
    "   - The derivatives with respect to \\(Z\\) yield:\n",
    "     - For \\(x\\):\n",
    "     $$\n",
    "     \\frac{\\partial x}{\\partial X} = \\frac{f_x}{Z}, \\quad \\frac{\\partial x}{\\partial Y} = 0, \\quad \\frac{\\partial x}{\\partial Z} = -\\frac{f_x \\cdot X}{Z^2}\n",
    "     $$\n",
    "     - For \\(y\\):\n",
    "     $$\n",
    "     \\frac{\\partial y}{\\partial X} = 0, \\quad \\frac{\\partial y}{\\partial Y} = \\frac{f_y}{Z}, \\quad \\frac{\\partial y}{\\partial Z} = -\\frac{f_y \\cdot Y}{Z^2}\n",
    "     $$\n",
    "\n",
    "3. **Forming the Jacobian**:\n",
    "   Using the derivatives calculated above, the Jacobian matrix \\(J\\) becomes:\n",
    "   $$\n",
    "   J = \\begin{bmatrix}\n",
    "   \\frac{f_x}{Z} & 0 & -\\frac{f_x \\cdot X}{Z^2} \\\\\n",
    "   0 & \\frac{f_y}{Z} & -\\frac{f_y \\cdot Y}{Z^2}\n",
    "   \\end{bmatrix}\n",
    "   $$\n",
    "\n",
    "\n",
    "### 2D Projection \n",
    "We calculate the conics coeffitient for each gaussian : $$Ax^2+Bxy+Cy^2 = 0$$, where $A = \\frac{\\sigma_y^2}{|V|}$, $B = \\frac{\\sigma_xy}{|V|}$ and  $C = \\frac{\\sigma_x^2}{|V|}$\n",
    "we then multiply by the distace between the gaussiam and the pixel. this is the same as: \n",
    "$-\\frac{1}{2} (\\mathbf{x} - \\mathbf{p})^T \\mathbf{V}^{-1} (\\mathbf{x} - \\mathbf{p})$ - the exponent of the gaussian\n",
    "\n",
    "wIncorporating the scaled conic, which represents the 2D Gaussian as an ellipse in the Gaussian equation, we can express the effect of every Gaussian on the pixel's color as follows:\n",
    "\n",
    "$$\n",
    "G_{\\mathbf{V}}(\\mathbf{x}) = \\frac{1}{(2\\pi)^{3/2} |\\mathbf{V}|^{1/2}} e^{-\\frac{1}{2} ( Ax^2+Bxy+Cy^2)}\n",
    "$$\n",
    "\n",
    "This equation captures how each Gaussian contributes to the pixel's color based on its distance from the pixel and the shape defined by the covariance matrix.\n",
    "\n",
    "## tiles\n",
    "To render the image we devide it to tiles of $ 16 X 16 $, for each tile we sort the gaussians according to the distance from the camera. we then sample all gaussians effect per pixel in the tile (using the power equation to calculate the opacity). We sum the gaussians color values and multiply by the opacity (doing alpha blending, each time we update the opacity according to the already calculated gaussians $color = RGB * \\alpha *\\alpha_{blend})$ were for eacg gaussian we add we update $\\alpha_{blend} =  \\alpha_{blend}*(1-\\alpha) $ (when we reach 0, its opaque). to later do the alpha blend we pick for each tile only the gaussians that intersect with the tile. since gaussians are not bounded, we bound them with 3 $\\sigma_x$ and 3 $\\sigma_y$ bounding box in each axis. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
